
<!DOCTYPE HTML>
<html>
<head>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
  <style>
    body {
      font-family: 'Roboto', sans-serif;
      background-color: #f5f5f5;
      margin: 0;
      padding: 20px;
      color: #333;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      background-color: #fff;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      padding: 24px;
      position: relative;
    }
    .header {
      text-align: center;
      margin-bottom: 32px;
    }
    .header h1 {
      font-size: 32px;
      font-weight: 700;
      color: #2c3e50;
      margin-bottom: 8px;
    }
    .header p {
      font-size: 16px;
      color: #666;
    }
    .paper-block {
      margin-bottom: 24px;
      padding: 16px;
      border-radius: 8px;
      background-color: #f9f9f9;
      border: 1px solid #ddd;
      opacity: 0;
      transform: translateY(20px);
      transition: opacity 0.6s ease, transform 0.6s ease;
    }
    .paper-block.visible {
      opacity: 1;
      transform: translateY(0);
    }
    .paper-title {
      font-size: 24px;
      font-weight: 700;
      color: #2c3e50;
      margin-bottom: 8px;
    }
    .paper-authors {
      font-size: 14px;
      color: #666;
      margin-bottom: 8px;
    }
    .paper-affiliations {
      font-size: 12px;
      color: #888;
      font-style: italic;
      margin-bottom: 8px;
    }
    .paper-tag {
      font-size: 14px;
      color: #333;
      margin-bottom: 8px;
    }
    .paper-score {
      font-size: 14px;
      color: #333;
      margin-bottom: 8px;
    }
    .paper-abstract {
      font-size: 14px;
      color: #444;
      line-height: 1.6;
      margin-bottom: 16px;
    }
    .paper-tldr {
      font-size: 14px;
      color: #444;
      line-height: 1.6;
      margin-bottom: 16px;
    }
    .paper-actions {
      display: flex;
      gap: 8px;
      align-items: center;
    }
    .paper-actions a {
      text-decoration: none;
      font-size: 14px;
      font-weight: 500;
      color: #fff;
      background-color: #3498db;
      padding: 8px 16px;
      border-radius: 4px;
      transition: background-color 0.3s ease;
    }
    .paper-actions a:hover {
      background-color: #2980b9;
    }
    .heart-btn {
      cursor: pointer;
      font-size: 24px;
      filter: grayscale(1) brightness(0.8);
      transition: filter 0.3s ease, transform 0.2s ease;
    }
    .heart-btn:hover {
      filter: grayscale(0.8) brightness(1);
      transform: scale(1.1);
    }
    .heart-btn.active {
      filter: grayscale(0) drop-shadow(0 0 4px rgba(231, 76, 60, 0.5));
    }
    .star-wrapper {
      font-size: 1.3em;
      line-height: 1;
      display: inline-flex;
      align-items: center;
    }
    .half-star {
      display: inline-block;
      width: 0.5em;
      overflow: hidden;
      white-space: nowrap;
      vertical-align: middle;
    }
    .full-star {
      vertical-align: middle;
    }
    .footer {
      text-align: center;
      font-size: 12px;
      color: #888;
      margin-top: 24px;
      padding-top: 16px;
      border-top: 1px solid #ddd;
    }
    .footer a {
      color: #3498db;
      text-decoration: none;
    }
    .footer a:hover {
      text-decoration: underline;
    }
    .back-to-top {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background-color: #3498db;
      color: #fff;
      padding: 10px 16px;
      border-radius: 50%;
      text-decoration: none;
      font-size: 18px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      transition: background-color 0.3s ease;
    }
    .back-to-top:hover {
      background-color: #2980b9;
    }
    /* Toast 提示条样式 */
    .toast {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background-color: #333;
      color: #fff;
      padding: 12px 24px;
      border-radius: 4px;
      font-size: 14px;
      opacity: 0;
      visibility: hidden;
      transition: opacity 0.3s ease, visibility 0.3s ease;
      z-index: 1000;
    }
    .toast.visible {
      opacity: 1;
      visibility: visible;
    }
    /* 模态框样式 */
    .modal {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.5);
      justify-content: center;
      align-items: center;
      z-index: 1000;
    }
    .modal.visible {
      display: flex;
    }
    .modal-content {
      background-color: #fff;
      border-radius: 8px;
      width: 90%;
      max-width: 800px;
      height: 80%;
      overflow: hidden;
      position: relative;
    }
    .modal-iframe {
      width: 100%;
      height: 100%;
      border: none;
    }
    .modal-actions {
      position: absolute;
      top: 10px;
      right: 10px;
      display: flex;
      gap: 8px;
    }
    .modal-button {
      background-color: #3498db;
      color: #fff;
      border: none;
      border-radius: 50%;
      width: 30px;
      height: 30px;
      font-size: 16px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: background-color 0.3s ease;
    }
    .modal-button:hover {
      background-color: #2980b9;
    }
    .modal-button.close {
      background-color: #e74c3c;
    }
    .modal-button.close:hover {
      background-color: #c0392b;
    }
    /* 提示条样式 */
    .browser-prompt {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      background-color: #3498db;
      color: #fff;
      padding: 12px;
      text-align: center;
      z-index: 1000;
      display: none;
      display: block;
    }
    .browser-prompt a {
      color: #fff;
      text-decoration: underline;
      margin-left: 8px;
    }
    .browser-prompt a:hover {
      color: #f1c40f;
    }
  </style>
</head>
<body>

<!-- 提示条 -->
<div class="browser-prompt" id="browser-prompt">
  For the best experience, please open this page in your browser.
  <a href="https://xiangsam.github.io/arxiv-daily/">Open in Browser</a>
</div>

<div class="container">
  <div class="header">
    <h1>Daily Research Papers</h1>
    <p>Your daily dose of the latest research papers, curated just for you.</p>
  </div>

  <div>
    <br>
    <div class="paper-block">
        <div class="paper-title">Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous Racing Systems</div>
        <div class="paper-authors">Zhenmin Huang, Ce Hao, Wei Zhan, Jun Ma, Masayoshi Tomizuka</div>
        <div class="paper-affiliations">The Hong Kong University of Science and Technology, University of California, Berkeley, National University of Singapore</div>
        <div class="paper-tag"><strong>Tag:</strong> Game-Theoretic Autonomous Racing</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Autonomous racing has gained significant attention as a platform for
high-speed decision-making and motion control. While existing methods primarily
focus on trajectory planning and overtaking strategies, the role of
sportsmanship in ensuring fair competition remains largely unexplored. In human
racing, rules such as the one-motion rule and the enough-space rule prevent
dangerous and unsportsmanlike behavior. However, autonomous racing systems
often lack mechanisms to enforce these principles, potentially leading to
unsafe maneuvers. This paper introduces a bi-level game-theoretic framework to
integrate sportsmanship (SPS) into versus racing. At the high level, we model
racing intentions using a Stackelberg game, where Monte Carlo Tree Search
(MCTS) is employed to derive optimal strategies. At the low level, vehicle
interactions are formulated as a Generalized Nash Equilibrium Problem (GNEP),
ensuring that all agents follow sportsmanship constraints while optimizing
their trajectories. Simulation results demonstrate the effectiveness of the
proposed approach in enforcing sportsmanship rules while maintaining
competitive performance. We analyze different scenarios where attackers and
defenders adhere to or disregard sportsmanship rules and show how knowledge of
these constraints influences strategic decision-making. This work highlights
the importance of balancing competition and fairness in autonomous racing and
provides a foundation for developing ethical and safe AI-driven racing systems.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper introduces a bi-level game-theoretic framework to integrate sportsmanship (SPS) into autonomous racing, using a Stackelberg game for high-level decision-making and a Generalized Nash Equilibrium Problem (GNEP) for low-level trajectory optimization, ensuring fairness and safety while maintaining competitive performance.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03774v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBFair+Play+in+the+Fast+Lane:+Integrating+Sportsmanship+into+Autonomous+Racing+Systems%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03774v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Sarcasm Detection as a Catalyst: Improving Stance Detection with Cross-Target Capabilities</div>
        <div class="paper-authors">Gibson Nkhata Shi Yin Hong, Susan Gauch</div>
        <div class="paper-affiliations">University of Arkansas</div>
        <div class="paper-tag"><strong>Tag:</strong> Intermediate-Task Transfer Learning</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Stance Detection (SD) has become a critical area of interest due to its
applications in various contexts leading to increased research within NLP. Yet
the subtlety and complexity of texts sourced from online platforms often
containing sarcastic language pose significant challenges for SD algorithms in
accurately determining the authors stance. This paper addresses this by
employing sarcasm for SD. It also tackles the issue of insufficient annotated
data for training SD models on new targets by conducting Cross-Target SD
(CTSD). The proposed approach involves fine-tuning BERT and RoBERTa models
followed by concatenating additional deep learning layers. The approach is
assessed against various State-Of-The-Art baselines for SD demonstrating
superior performance using publicly available datasets. Notably our model
outperforms the best SOTA models on both in-domain SD and CTSD tasks even
before the incorporation of sarcasm-detection pre-training. The integration of
sarcasm knowledge into the model significantly reduces misclassifications of
sarcastic text elements in SD allowing our model to accurately predict 85% of
texts that were previously misclassified without sarcasm-detection pre-training
on in-domain SD. This enhancement contributes to an increase in the models
average macro F1-score. The CTSD task achieves performance comparable to that
of the in-domain task despite using a zero-shot finetuning. We also reveal that
the success of the transfer-learning framework relies on the correlation
between the lexical attributes of sarcasm detection and SD. This study
represents the first exploration of sarcasm detection as an intermediate
transfer-learning task within the context of SD while also leveraging the
concatenation of BERT or RoBERTa with other deep-learning techniques. The
proposed approach establishes a foundational baseline for future research in
this domain.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper introduces a novel transfer-learning framework that leverages sarcasm detection as an intermediate task to enhance Stance Detection (SD), achieving superior performance in both in-domain and Cross-Target SD tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03787v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBSarcasm+Detection+as+a+Catalyst:+Improving+Stance+Detection+with+Cross-Target+Capabilities%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03787v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Predicting Team Performance from Communications in Simulated Search-and-Rescue</div>
        <div class="paper-authors">Ali Jalal-Kamali, Nikolos Gurney, David Pynadath</div>
        <div class="paper-affiliations">University of Southern California, Rice University</div>
        <div class="paper-tag"><strong>Tag:</strong> Team Communication Analysis in AI</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Understanding how individual traits influence team performance is valuable,
but these traits are not always directly observable. Prior research has
inferred traits like trust from behavioral data. We analyze conversational data
to identify team traits and their correlation with teaming outcomes. Using
transcripts from a Minecraft-based search-and-rescue experiment, we apply topic
modeling and clustering to uncover key interaction patterns. Our findings show
that variations in teaming outcomes can be explained through these inferences,
with different levels of predictive power derived from individual traits and
team dynamics.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper analyzes conversational data from a Minecraft-based search-and-rescue experiment to predict team performance by identifying key interaction patterns and individual traits.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03791v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBPredicting+Team+Performance+from+Communications+in+Simulated+Search-and-Rescue%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03791v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Vision-Language Models Struggle to Align Entities across Modalities</div>
        <div class="paper-authors">Iñigo Alonso, Ander Salaberria, Gorka Azkune, Jeremy Barnes, Oier Lopez de Lacalle</div>
        <div class="paper-affiliations">University of Edinburgh, University of the Basque Country UPV/EHU</div>
        <div class="paper-tag"><strong>Tag:</strong> Cross-Modal Entity Linking</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Cross-modal entity linking refers to the ability to align entities and their
attributes across different modalities. While cross-modal entity linking is a
fundamental skill needed for real-world applications such as multimodal code
generation, fake news detection, or scene understanding, it has not been
thoroughly studied in the literature. In this paper, we introduce a new task
and benchmark to address this gap. Our benchmark, MATE, consists of 5.5k
evaluation instances featuring visual scenes aligned with their textual
representations. To evaluate cross-modal entity linking performance, we design
a question-answering task that involves retrieving one attribute of an object
in one modality based on a unique attribute of that object in another modality.
We evaluate state-of-the-art Vision-Language Models (VLMs) and humans on this
task, and find that VLMs struggle significantly compared to humans,
particularly as the number of objects in the scene increases. Our analysis also
shows that, while chain-of-thought prompting can improve VLM performance,
models remain far from achieving human-level proficiency. These findings
highlight the need for further research in cross-modal entity linking and show
that MATE is a strong benchmark to support that progress.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Vision-Language Models (VLMs) struggle with cross-modal entity linking, particularly as scene complexity increases, despite improvements with chain-of-thought prompting, highlighting the need for further research in this area.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03854v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBVision-Language+Models+Struggle+to+Align+Entities+across+Modalities%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03854v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream Impact of Language Model Design Decisions</div>
        <div class="paper-authors">Emmy Liu, Amanda Bertsch, Lintang Sutawika, Lindia Tjuatja, Patrick Fernandes, ...</div>
        <div class="paper-affiliations">Carnegie Mellon University, Instituto Superior Técnico, NEC Laboratories Europe, Instituto de Telecomunicações, Center for Advanced Interdisciplinary Research</div>
        <div class="paper-tag"><strong>Tag:</strong> Language Model Data Composition</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Improvements in language model capabilities are often attributed to
increasing model size or training data, but in some cases smaller models
trained on curated data or with different architectural decisions can
outperform larger ones trained on more tokens. What accounts for this? To
quantify the impact of these design choices, we meta-analyze 92 open-source
pretrained models across a wide array of scales, including state-of-the-art
open-weights models as well as less performant models and those with less
conventional design decisions. We find that by incorporating features besides
model size and number of training tokens, we can achieve a relative 3-28%
increase in ability to predict downstream performance compared with using scale
alone. Analysis of model design decisions reveal insights into data
composition, such as the trade-off between language and code tasks at 15-25\%
code, as well as the better performance of some architectural decisions such as
choosing rotary over learned embeddings. Broadly, our framework lays a
foundation for more systematic investigation of how model development choices
shape final capabilities.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper demonstrates that incorporating features beyond model size and training data, such as data composition and architectural decisions, improves the prediction of downstream performance in language models by 3-28%.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03862v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBNot-Just-Scaling+Laws:+Towards+a+Better+Understanding+of+the+Downstream+Impact+of+Language+Model+Design+Decisions%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03862v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Learning to Negotiate via Voluntary Commitment</div>
        <div class="paper-authors">Shuhui Zhu, Baoxiang Wang, Sriram Ganapathi Subramanian, Pascal Poupart</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Multi-Agent Reinforcement Learning</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The partial alignment and conflict of autonomous agents lead to mixed-motive
scenarios in many real-world applications. However, agents may fail to
cooperate in practice even when cooperation yields a better outcome. One well
known reason for this failure comes from non-credible commitments. To
facilitate commitments among agents for better cooperation, we define Markov
Commitment Games (MCGs), a variant of commitment games, where agents can
voluntarily commit to their proposed future plans. Based on MCGs, we propose a
learnable commitment protocol via policy gradients. We further propose
incentive-compatible learning to accelerate convergence to equilibria with
better social welfare. Experimental results in challenging mixed-motive tasks
demonstrate faster empirical convergence and higher returns for our method
compared with its counterparts. Our code is available at
https://github.com/shuhui-zhu/DCL.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Markov Commitment Games (MCGs) and a learnable commitment protocol, differentiable commitment learning (DCL), to enhance cooperation among self-interested agents in mixed-motive scenarios.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03866v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLearning+to+Negotiate+via+Voluntary+Commitment%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03866v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">AI for Scaling Legal Reform: Mapping and Redacting Racial Covenants in Santa Clara County</div>
        <div class="paper-authors">Faiz Surani, Mirac Suzgun, Vyoma Raman, Christopher D. Manning, Peter Henderson, ...</div>
        <div class="paper-affiliations">Princeton University, Stanford University</div>
        <div class="paper-tag"><strong>Tag:</strong> AI for Legal Document Analysis</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Many jurisdictions have moved to identify and strike these provisions,
including California, which mandated in 2021 that all counties implement such a
process. Yet the scale can be overwhelming, with Santa Clara County (SCC) alone
having over 24 million property deed documents, making purely manual review
infeasible. We present a novel approach to addressing this pressing issue,
developed through a partnership with the SCC Clerk-Recorder's Office. First, we
leverage an open large language model, fine-tuned to detect racial covenants
with high precision and recall. We estimate that this system reduces manual
efforts by 86,500 person hours and costs less than 2% of the cost for a
comparable off-the-shelf closed model. Second, we illustrate the County's
integration of this model into responsible operational practice, including
legal review and the creation of a historical registry, and release our model
to assist the hundreds of jurisdictions engaged in similar efforts. Finally,
our results reveal distinct periods of utilization of racial covenants, sharp
geographic clustering, and the disproportionate role of a small number of
developers in maintaining housing discrimination. We estimate that by 1950, one
in four properties across the County were subject to racial covenants.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper presents an AI-driven approach using fine-tuned large language models to efficiently identify and redact racial covenants in property deeds, significantly reducing manual effort and cost while preserving historical records.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03888v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAI+for+Scaling+Legal+Reform:+Mapping+and+Redacting+Racial+Covenants+in+Santa+Clara+County%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03888v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Tec-Habilidad: Skill Classification for Bridging Education and Employment</div>
        <div class="paper-authors">Sabur Butt, Hector G. Ceballos, Diana P. Madera</div>
        <div class="paper-affiliations">Tecnológico de Monterrey</div>
        <div class="paper-tag"><strong>Tag:</strong> Skill Extraction in Multilingual NLP</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Job application and assessment processes have evolved significantly in recent
years, largely due to advancements in technology and changes in the way
companies operate. Skill extraction and classification remain an important
component of the modern hiring process as it provides a more objective way to
evaluate candidates and automatically align their skills with the job
requirements. However, to effectively evaluate the skills, the skill extraction
tools must recognize varied mentions of skills on resumes, including direct
mentions, implications, synonyms, acronyms, phrases, and proficiency levels,
and differentiate between hard and soft skills. While tools like LLMs (Large
Model Models) help extract and categorize skills from job applications, there's
a lack of comprehensive datasets for evaluating the effectiveness of these
models in accurately identifying and classifying skills in Spanish-language job
applications. This gap hinders our ability to assess the reliability and
precision of the models, which is crucial for ensuring that the selected
candidates truly possess the required skills for the job. In this paper, we
develop a Spanish language dataset for skill extraction and classification,
provide annotation methodology to distinguish between knowledge, skill, and
abilities, and provide deep learning baselines to advance robust solutions for
skill classification.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper introduces a Spanish-language dataset for skill extraction and classification, leveraging transformer models to achieve high accuracy in automating skill classification tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03932v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTec-Habilidad:+Skill+Classification+for+Bridging+Education+and+Employment%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03932v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Performance Comparison of Large Language Models on Advanced Calculus Problems</div>
        <div class="paper-authors">In Hak Moon</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Mathematical Problem-Solving</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> This paper presents an in-depth analysis of the performance of seven
different Large Language Models (LLMs) in solving a diverse set of math
advanced calculus problems. The study aims to evaluate these models' accuracy,
reliability, and problem-solving capabilities, including ChatGPT 4o, Gemini
Advanced with 1.5 Pro, Copilot Pro, Claude 3.5 Sonnet, Meta AI, Mistral AI, and
Perplexity. The assessment was conducted through a series of thirty-two test
problems, encompassing a total of 320 points. The problems covered various
topics, from vector calculations and geometric interpretations to integral
evaluations and optimization tasks. The results highlight significant trends
and patterns in the models' performance, revealing both their strengths and
weaknesses - for instance, models like ChatGPT 4o and Mistral AI demonstrated
consistent accuracy across various problem types, indicating their robustness
and reliability in mathematical problem-solving, while models such as Gemini
Advanced with 1.5 Pro and Meta AI exhibited specific weaknesses, particularly
in complex problems involving integrals and optimization, suggesting areas for
targeted improvements. The study also underscores the importance of
re-prompting in achieving accurate solutions, as seen in several instances
where models initially provided incorrect answers but corrected them upon
re-prompting. Overall, this research provides valuable insights into the
current capabilities and limitations of LLMs in the domain of math calculus,
with the detailed analysis of each model's performance on specific problems
offering a comprehensive understanding of their strengths and areas for
improvement, contributing to the ongoing development and refinement of LLM
technology. The findings are particularly relevant for educators, researchers,
and developers seeking to leverage LLMs for educational and practical
applications in mathematics.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper compares the performance of seven Large Language Models on advanced calculus problems, revealing strengths and weaknesses in their accuracy and problem-solving capabilities.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03960v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBPerformance+Comparison+of+Large+Language+Models+on+Advanced+Calculus+Problems%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03960v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">On the Acquisition of Shared Grammatical Representations in Bilingual Language Models</div>
        <div class="paper-authors">Catherine Arnett, Tyler A. Chang, James A. Michaelov, Benjamin K. Bergen</div>
        <div class="paper-affiliations">Massachusetts Institute of Technology, University of California San Diego</div>
        <div class="paper-tag"><strong>Tag:</strong> Crosslingual Structural Priming</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> While crosslingual transfer is crucial to contemporary language models'
multilingual capabilities, how it occurs is not well understood. In this paper,
we ask what happens to a monolingual language model when it begins to be
trained on a second language. Specifically, we train small bilingual models for
which we control the amount of data for each language and the order of language
exposure. To find evidence of shared multilingual representations, we turn to
structural priming, a method used to study grammatical representations in
humans. We first replicate previous crosslingual structural priming results and
find that after controlling for training data quantity and language exposure,
there are asymmetrical effects across language pairs and directions. We argue
that this asymmetry may shape hypotheses about human structural priming
effects. We also find that structural priming effects are less robust for less
similar language pairs, highlighting potential limitations of crosslingual
transfer learning and shared representations for typologically diverse
languages.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper investigates how bilingual language models acquire shared grammatical representations through structural priming, revealing asymmetrical effects based on language similarity and acquisition order.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03962v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBOn+the+Acquisition+of+Shared+Grammatical+Representations+in+Bilingual+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03962v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">ReasonGraph: Visualisation of Reasoning Paths</div>
        <div class="paper-authors">Zongqian Li, Ehsan Shareghi, Nigel Collier</div>
        <div class="paper-affiliations">Monash University, University of Cambridge</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Reasoning Visualization</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Models (LLMs) reasoning processes are challenging to analyze
due to their complexity and the lack of organized visualization tools. We
present ReasonGraph, a web-based platform for visualizing and analyzing LLM
reasoning processes. It supports both sequential and tree-based reasoning
methods while integrating with major LLM providers and over fifty
state-of-the-art models. ReasonGraph incorporates an intuitive UI with meta
reasoning method selection, configurable visualization parameters, and a
modular framework that facilitates efficient extension. Our evaluation shows
high parsing reliability, efficient processing, and strong usability across
various downstream applications. By providing a unified visualization
framework, ReasonGraph reduces cognitive load in analyzing complex reasoning
paths, improves error detection in logical processes, and enables more
effective development of LLM-based applications. The platform is open-source,
promoting accessibility and reproducibility in LLM reasoning analysis.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> ReasonGraph is a web-based platform for visualizing and analyzing LLM reasoning processes, offering a unified, modular, and extensible framework to reduce cognitive load, improve error detection, and enhance LLM-based applications.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.03979v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBReasonGraph:+Visualisation+of+Reasoning+Paths%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.03979v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Benchmarking Large Language Models on Multiple Tasks in Bioinformatics NLP with Prompting</div>
        <div class="paper-authors">Jiyue Jiang, Pengan Chen, Jiuming Wang, Dongchen He, Ziqin Wei, ...</div>
        <div class="paper-affiliations">The University of Hong Kong, Shanghai AI Lab, The Chinese University of Hong Kong</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Prompt Engineering in Bioinformatics</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large language models (LLMs) have become important tools in solving
biological problems, offering improvements in accuracy and adaptability over
conventional methods. Several benchmarks have been proposed to evaluate the
performance of these LLMs. However, current benchmarks can hardly evaluate the
performance of these models across diverse tasks effectively. In this paper, we
introduce a comprehensive prompting-based benchmarking framework, termed
Bio-benchmark, which includes 30 key bioinformatics tasks covering areas such
as proteins, RNA, drugs, electronic health records, and traditional Chinese
medicine. Using this benchmark, we evaluate six mainstream LLMs, including
GPT-4o and Llama-3.1-70b, etc., using 0-shot and few-shot Chain-of-Thought
(CoT) settings without fine-tuning to reveal their intrinsic capabilities. To
improve the efficiency of our evaluations, we demonstrate BioFinder, a new tool
for extracting answers from LLM responses, which increases extraction accuracy
by round 30% compared to existing methods. Our benchmark results show the
biological tasks suitable for current LLMs and identify specific areas
requiring enhancement. Furthermore, we propose targeted prompt engineering
strategies for optimizing LLM performance in these contexts. Based on these
findings, we provide recommendations for the development of more robust LLMs
tailored for various biological applications. This work offers a comprehensive
evaluation framework and robust tools to support the application of LLMs in
bioinformatics.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Bio-benchmark, a comprehensive prompting-based framework to evaluate the performance of six large language models (LLMs) on 30 bioinformatics tasks, and proposes BioFinder, a tool for accurate answer extraction from LLM responses.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04013v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBBenchmarking+Large+Language+Models+on+Multiple+Tasks+in+Bioinformatics+NLP+with+Prompting%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04013v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Uncovering inequalities in new knowledge learning by large language models across different languages</div>
        <div class="paper-authors">Chenglong Wang, Haoyu Tang, Xiyuan Yang, Yueqi Xie, Jina Suh, ...</div>
        <div class="paper-affiliations">University of Science and Technology of China, Princeton University, Microsoft Research Asia, Microsoft Research, Peking University, ...</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Linguistic Inequality</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> As large language models (LLMs) gradually become integral tools for problem
solving in daily life worldwide, understanding linguistic inequality is
becoming increasingly important. Existing research has primarily focused on
static analyses that assess the disparities in the existing knowledge and
capabilities of LLMs across languages. However, LLMs are continuously evolving,
acquiring new knowledge to generate up-to-date, domain-specific responses.
Investigating linguistic inequalities within this dynamic process is,
therefore, also essential. In this paper, we explore inequalities in new
knowledge learning by LLMs across different languages and four key dimensions:
effectiveness, transferability, prioritization, and robustness. Through
extensive experiments under two settings (in-context learning and fine-tuning)
using both proprietary and open-source models, we demonstrate that low-resource
languages consistently face disadvantages across all four dimensions. By
shedding light on these disparities, we aim to raise awareness of linguistic
inequalities in LLMs' new knowledge learning, fostering the development of more
inclusive and equitable future LLMs.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper investigates linguistic inequalities in new knowledge learning by large language models across different languages, revealing consistent disadvantages for low-resource languages in effectiveness, transferability, prioritization, and robustness.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04064v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBUncovering+inequalities+in+new+knowledge+learning+by+large+language+models+across+different+languages%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04064v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">SED2AM: Solving Multi-Trip Time-Dependent Vehicle Routing Problem using Deep Reinforcement Learning</div>
        <div class="paper-authors">Arash Mozhdehi, Yunli Wang, Sun Sun, Xin Wang</div>
        <div class="paper-affiliations">National Research Council Canada, University of Calgary</div>
        <div class="paper-tag"><strong>Tag:</strong> Transformer-based Policy Networks in Vehicle Routing Problems</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Deep reinforcement learning (DRL)-based frameworks, featuring
Transformer-style policy networks, have demonstrated their efficacy across
various vehicle routing problem (VRP) variants. However, the application of
these methods to the multi-trip time-dependent vehicle routing problem
(MTTDVRP) with maximum working hours constraints -- a pivotal element of urban
logistics -- remains largely unexplored. This paper introduces a DRL-based
method called the Simultaneous Encoder and Dual Decoder Attention Model
(SED2AM), tailored for the MTTDVRP with maximum working hours constraints. The
proposed method introduces a temporal locality inductive bias to the encoding
module of the policy networks, enabling it to effectively account for the
time-dependency in travel distance or time. The decoding module of SED2AM
includes a vehicle selection decoder that selects a vehicle from the fleet,
effectively associating trips with vehicles for functional multi-trip routing.
Additionally, this decoding module is equipped with a trip construction decoder
leveraged for constructing trips for the vehicles. This policy model is
equipped with two classes of state representations, fleet state and routing
state, providing the information needed for effective route construction in the
presence of maximum working hours constraints. Experimental results using
real-world datasets from two major Canadian cities not only show that SED2AM
outperforms the current state-of-the-art DRL-based and metaheuristic-based
baselines but also demonstrate its generalizability to solve larger-scale
problems.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> SED2AM is a deep reinforcement learning-based method that effectively solves the multi-trip time-dependent vehicle routing problem with maximum working hours constraints by incorporating a Transformer-style policy model and a dual-decoding module.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04085v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBSED2AM:+Solving+Multi-Trip+Time-Dependent+Vehicle+Routing+Problem+using+Deep+Reinforcement+Learning%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04085v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Chart-HQA: A Benchmark for Hypothetical Question Answering in Charts</div>
        <div class="paper-authors">Xiangnan Chen, Yuancheng Fang, Qian Xiao, Juncheng Li, Jun Lin, ...</div>
        <div class="paper-affiliations">Alibaba Group, Zhejiang University</div>
        <div class="paper-tag"><strong>Tag:</strong> Multimodal Large Language Models (MLLMs) in Chart Understanding</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Multimodal Large Language Models (MLLMs) have garnered significant attention
for their strong visual-semantic understanding. Most existing chart benchmarks
evaluate MLLMs' ability to parse information from charts to answer
questions.However, they overlook the inherent output biases of MLLMs, where
models rely on their parametric memory to answer questions rather than
genuinely understanding the chart content. To address this limitation, we
introduce a novel Chart Hypothetical Question Answering (HQA) task, which
imposes assumptions on the same question to compel models to engage in
counterfactual reasoning based on the chart content. Furthermore, we introduce
HAI, a human-AI interactive data synthesis approach that leverages the
efficient text-editing capabilities of LLMs alongside human expert knowledge to
generate diverse and high-quality HQA data at a low cost. Using HAI, we
construct Chart-HQA, a challenging benchmark synthesized from publicly
available data sources. Evaluation results on 18 MLLMs of varying model sizes
reveal that current models face significant generalization challenges and
exhibit imbalanced reasoning performance on the HQA task.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Chart-HQA, a benchmark for evaluating Multimodal Large Language Models (MLLMs) on hypothetical question answering in charts, revealing their limitations in counterfactual reasoning and visual chart understanding.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04095v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBChart-HQA:+A+Benchmark+for+Hypothetical+Question+Answering+in+Charts%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04095v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Disparities in LLM Reasoning Accuracy and Explanations: A Case Study on African American English</div>
        <div class="paper-authors">Runtao Zhou, Guangya Wan, Saadia Gabriel, Sheng Li, Alexander J Gates, ...</div>
        <div class="paper-affiliations">Carnegie Mellon University, University of Virginia, University of California, Los Angeles</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Dialectal Bias Mitigation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Models (LLMs) have demonstrated remarkable capabilities in
reasoning tasks, leading to their widespread deployment. However, recent
studies have highlighted concerning biases in these models, particularly in
their handling of dialectal variations like African American English (AAE). In
this work, we systematically investigate dialectal disparities in LLM reasoning
tasks. We develop an experimental framework comparing LLM performance given
Standard American English (SAE) and AAE prompts, combining LLM-based dialect
conversion with established linguistic analyses. We find that LLMs consistently
produce less accurate responses and simpler reasoning chains and explanations
for AAE inputs compared to equivalent SAE questions, with disparities most
pronounced in social science and humanities domains. These findings highlight
systematic differences in how LLMs process and reason about different language
varieties, raising important questions about the development and deployment of
these systems in our multilingual and multidialectal world. Our code repository
is publicly available at https://github.com/Runtaozhou/dialect_bias_eval.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> LLMs exhibit significant dialectal biases, producing less accurate and simpler reasoning for African American English (AAE) compared to Standard American English (SAE), particularly in social science and humanities domains.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04099v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDisparities+in+LLM+Reasoning+Accuracy+and+Explanations:+A+Case+Study+on+African+American+English%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04099v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">LLMs Can Generate a Better Answer by Aggregating Their Own Responses</div>
        <div class="paper-authors">Zichong Li, Xinyu Feng, Yuheng Cai, Zixuan Zhang, Tianyi Liu, ...</div>
        <div class="paper-affiliations">University at Albany, Microsoft Azure, Georgia Tech, Amazon</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Response Aggregation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Models (LLMs) have shown remarkable capabilities across tasks,
yet they often require additional prompting techniques when facing complex
problems. While approaches like self-correction and response selection have
emerged as popular solutions, recent studies have shown these methods perform
poorly when relying on the LLM itself to provide feedback or selection
criteria. We argue this limitation stems from the fact that common LLM
post-training procedures lack explicit supervision for discriminative judgment
tasks. In this paper, we propose Generative Self-Aggregation (GSA), a novel
prompting method that improves answer quality without requiring the model's
discriminative capabilities. GSA first samples multiple diverse responses from
the LLM, then aggregates them to obtain an improved solution. Unlike previous
approaches, our method does not require the LLM to correct errors or compare
response quality; instead, it leverages the model's generative abilities to
synthesize a new response based on the context of multiple samples. While GSA
shares similarities with the self-consistency (SC) approach for response
aggregation, SC requires specific verifiable tokens to enable majority voting.
In contrast, our approach is more general and can be applied to open-ended
tasks. Empirical evaluation demonstrates that GSA effectively improves response
quality across various tasks, including mathematical reasoning, knowledge-based
problems, and open-ended generation tasks such as code synthesis and
conversational responses.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Generative Self-Aggregation (GSA) improves LLM performance by aggregating multiple diverse responses without requiring discriminative judgments or additional training.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04104v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLLMs+Can+Generate+a+Better+Answer+by+Aggregating+Their+Own+Responses%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04104v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Uncovering Gaps in How Humans and LLMs Interpret Subjective Language</div>
        <div class="paper-authors">Erik Jones, Arjun Patrawala, Jacob Steinhardt</div>
        <div class="paper-affiliations">UC Berkeley</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Operational Semantics</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Humans often rely on subjective natural language to direct language models
(LLMs); for example, users might instruct the LLM to write an enthusiastic
blogpost, while developers might train models to be helpful and harmless using
LLM-based edits. The LLM's operational semantics of such subjective phrases --
how it adjusts its behavior when each phrase is included in the prompt -- thus
dictates how aligned it is with human intent. In this work, we uncover
instances of misalignment between LLMs' actual operational semantics and what
humans expect. Our method, TED (thesaurus error detector), first constructs a
thesaurus that captures whether two phrases have similar operational semantics
according to the LLM. It then elicits failures by unearthing disagreements
between this thesaurus and a human-constructed reference. TED routinely
produces surprising instances of misalignment; for example, Mistral 7B Instruct
produces more harassing outputs when it edits text to be witty, and Llama 3 8B
Instruct produces dishonest articles when instructed to make the articles
enthusiastic. Our results demonstrate that humans can uncover unexpected LLM
behavior by scrutinizing relationships between abstract concepts, without
supervising outputs directly.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces TED (Thesaurus Error Detector) to uncover misalignment between LLMs' operational semantics of subjective language and human expectations, revealing unexpected behaviors like increased harassment or dishonesty in outputs.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04113v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBUncovering+Gaps+in+How+Humans+and+LLMs+Interpret+Subjective+Language%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04113v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Artificial Intelligence in Pronunciation Teaching: Use and Beliefs of Foreign Language Teachers</div>
        <div class="paper-authors">Georgios P. Georgiou</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> AI in Language Education</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Pronunciation instruction in foreign language classrooms has often been an
overlooked area of focus. With the widespread adoption of Artificial
Intelligence (AI) and its potential benefits, investigating how AI is utilized
in pronunciation teaching and understanding the beliefs of teachers about this
tool is essential for improving learning outcomes. This study aims to examine
how AI use for pronunciation instruction varies across different demographic
and professional factors among teachers, and how these factors, including AI
use, influence the beliefs of teachers about AI. The study involved 117 English
as a Foreign Language (EFL) in-service teachers working in Cyprus, who
completed an online survey designed to assess their beliefs about the
effectiveness of AI, its drawbacks, and their willingness to integrate AI into
their teaching practices. The results revealed that teachers were significantly
more likely to agree on the perceived effectiveness of AI and their willingness
to adopt it, compared to their concerns about its use. Furthermore, teachers
working in higher education and adult education, as well as those who had
received more extensive training, reported using AI more frequently in their
teaching. Teachers who utilized AI more often expressed stronger agreement with
its effectiveness, while those who had received more training were less likely
to express concerns about its integration. Given the limited training that many
teachers currently receive, these findings demonstrate the need for tailored
training sessions that address the specific needs and concerns of educators,
ultimately fostering the adoption of AI in pronunciation instruction.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Foreign language teachers in Cyprus generally perceive AI as effective for pronunciation instruction and are willing to adopt it, with higher usage and positive beliefs linked to more training and teaching in higher education.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04128v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBArtificial+Intelligence+in+Pronunciation+Teaching:+Use+and+Beliefs+of+Foreign+Language+Teachers%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04128v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Biological Sequence with Language Model Prompting: A Survey</div>
        <div class="paper-authors">Jiyue Jiang, Zikang Wang, Yuheng Shan, Heyan Chai, Jiayi Li, ...</div>
        <div class="paper-affiliations">The Hong Kong Polytechnic University, National University of Singapore, The Chinese University of Hong Kong</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Prompt Engineering in Bioinformatics</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language models (LLMs) have emerged as powerful tools for addressing
challenges across diverse domains. Notably, recent studies have demonstrated
that large language models significantly enhance the efficiency of biomolecular
analysis and synthesis, attracting widespread attention from academics and
medicine. In this paper, we systematically investigate the application of
prompt-based methods with LLMs to biological sequences, including DNA, RNA,
proteins, and drug discovery tasks. Specifically, we focus on how prompt
engineering enables LLMs to tackle domain-specific problems, such as promoter
sequence prediction, protein structure modeling, and drug-target binding
affinity prediction, often with limited labeled data. Furthermore, our
discussion highlights the transformative potential of prompting in
bioinformatics while addressing key challenges such as data scarcity,
multimodal fusion, and computational resource limitations. Our aim is for this
paper to function both as a foundational primer for newcomers and a catalyst
for continued innovation within this dynamic field of study.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This survey explores the application of prompt-based methods with large language models (LLMs) in biological sequence analysis, highlighting their potential in tasks like DNA, RNA, protein, and drug discovery with limited labeled data.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04135v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBBiological+Sequence+with+Language+Model+Prompting:+A+Survey%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04135v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Ticktack : Long Span Temporal Alignment of Large Language Models Leveraging Sexagenary Cycle Time Expression</div>
        <div class="paper-authors">Xue Han, Qian Hu, Yitong Wang, Wenchun Gao, Lianlian Zhang, ...</div>
        <div class="paper-affiliations">China Mobile Research Institute</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Temporal Alignment</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large language models (LLMs) suffer from temporal misalignment issues
especially across long span of time. The issue arises from knowing that LLMs
are trained on large amounts of data where temporal information is rather
sparse over long times, such as thousands of years, resulting in insufficient
learning or catastrophic forgetting by the LLMs. This paper proposes a
methodology named "Ticktack" for addressing the LLM's long-time span
misalignment in a yearly setting. Specifically, we first propose to utilize the
sexagenary year expression instead of the Gregorian year expression employed by
LLMs, achieving a more uniform distribution in yearly granularity. Then, we
employ polar coordinates to model the sexagenary cycle of 60 terms and the year
order within each term, with additional temporal encoding to ensure LLMs
understand them. Finally, we present a temporal representational alignment
approach for post-training LLMs that effectively distinguishes time points with
relevant knowledge, hence improving performance on time-related tasks,
particularly over a long period. We also create a long time span benchmark for
evaluation. Experimental results prove the effectiveness of our proposal.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces 'Ticktack', a method using sexagenary cycle time expression and polar coordinates to improve long-span temporal alignment in large language models, enhancing performance on time-related tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04150v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTicktack+:+Long+Span+Temporal+Alignment+of+Large+Language+Models+Leveraging+Sexagenary+Cycle+Time+Expression%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04150v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease</div>
        <div class="paper-authors">Yongchao Long, Chao Yang, Gongzheng Tang, Jinwei Wang, Zhun Sui, ...</div>
        <div class="paper-affiliations">Tsinghua University, Peking University First Hospital, Peking University, Tianjin University of Technology, Peking University People's Hospital, ...</div>
        <div class="paper-tag"><strong>Tag:</strong> Medical LLM Deployment</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Privacy-preserving medical decision support for kidney disease requires
localized deployment of large language models (LLMs) while maintaining clinical
reasoning capabilities. Current solutions face three challenges: 1) Cloud-based
LLMs pose data security risks; 2) Local model deployment demands technical
expertise; 3) General LLMs lack mechanisms to integrate medical knowledge.
Retrieval-augmented systems also struggle with medical document processing and
clinical usability. We developed KidneyTalk-open, a desktop system integrating
three technical components: 1) No-code deployment of state-of-the-art (SOTA)
open-source LLMs (such as DeepSeek-r1, Qwen2.5) via local inference engine; 2)
Medical document processing pipeline combining context-aware chunking and
intelligent filtering; 3) Adaptive Retrieval and Augmentation Pipeline (AddRep)
employing agents collaboration for improving the recall rate of medical
documents. A graphical interface was designed to enable clinicians to manage
medical documents and conduct AI-powered consultations without technical
expertise. Experimental validation on 1,455 challenging nephrology exam
questions demonstrates AddRep's effectiveness: achieving 29.1% accuracy (+8.1%
over baseline) with intelligent knowledge integration, while maintaining
robustness through 4.9% rejection rate to suppress hallucinations. Comparative
case studies with the mainstream products (AnythingLLM, Chatbox, GPT4ALL)
demonstrate KidneyTalk-open's superior performance in real clinical query.
KidneyTalk-open represents the first no-code medical LLM system enabling secure
documentation-enhanced medical Q&A on desktop. Its designs establishes a new
framework for privacy-sensitive clinical AI applications. The system
significantly lowers technical barriers while improving evidence traceability,
enabling more medical staff or patients to use SOTA open-source LLMs
conveniently.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> KidneyTalk-open is a no-code, privacy-preserving desktop system that integrates open-source LLMs with a medical documentation-enhanced knowledge database for kidney disease, enabling secure and accessible AI-powered medical consultations.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04153v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBKidneyTalk-open:+No-code+Deployment+of+a+Private+Large+Language+Model+with+Medical+Documentation-Enhanced+Knowledge+Database+for+Kidney+Disease%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04153v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">BPQA Dataset: Evaluating How Well Language Models Leverage Blood Pressures to Answer Biomedical Questions</div>
        <div class="paper-authors">Chi Hang, Ruiqi Deng, Lavender Yao Jiang, Zihao Yang, Anton Alyakin, ...</div>
        <div class="paper-affiliations">NYU Center for Data Science, NYU Grossman School of Medicine, Washington University, Saint Louis, NYU Langone Health</div>
        <div class="paper-tag"><strong>Tag:</strong> Clinical Measurement Interpretation in Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Clinical measurements such as blood pressures and respiration rates are
critical in diagnosing and monitoring patient outcomes. It is an important
component of biomedical data, which can be used to train transformer-based
language models (LMs) for improving healthcare delivery. It is, however,
unclear whether LMs can effectively interpret and use clinical measurements. We
investigate two questions: First, can LMs effectively leverage clinical
measurements to answer related medical questions? Second, how to enhance an
LM's performance on medical question-answering (QA) tasks that involve
measurements? We performed a case study on blood pressure readings (BPs), a
vital sign routinely monitored by medical professionals. We evaluated the
performance of four LMs: BERT, BioBERT, MedAlpaca, and GPT-3.5, on our newly
developed dataset, BPQA (Blood Pressure Question Answering). BPQA contains
$100$ medical QA pairs that were verified by medical students and designed to
rely on BPs . We found that GPT-3.5 and MedAlpaca (larger and medium sized LMs)
benefit more from the inclusion of BPs than BERT and BioBERT (small sized LMs).
Further, augmenting measurements with labels improves the performance of
BioBERT and Medalpaca (domain specific LMs), suggesting that retrieval may be
useful for improving domain-specific LMs.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The BPQA dataset evaluates how well language models (LMs) like GPT-3.5, MedAlpaca, BERT, and BioBERT leverage blood pressure readings to answer biomedical questions, finding that larger and domain-specific LMs benefit more from including BP measurements and that augmenting measurements with labels improves performance.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04155v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBBPQA+Dataset:+Evaluating+How+Well+Language+Models+Leverage+Blood+Pressures+to+Answer+Biomedical+Questions%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04155v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">TIMER: Temporal Instruction Modeling and Evaluation for Longitudinal Clinical Records</div>
        <div class="paper-authors">Hejie Cui, Alyssa Unell, Bowen Chen, Jason Alan Fries, Emily Alsentzer, ...</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Temporal Reasoning in Clinical Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large language models (LLMs) have emerged as promising tools for assisting in
medical tasks, yet processing Electronic Health Records (EHRs) presents unique
challenges due to their longitudinal nature. While LLMs' capabilities to
perform medical tasks continue to improve, their ability to reason over
temporal dependencies across multiple patient visits and time frames remains
unexplored. We introduce TIMER (Temporal Instruction Modeling and Evaluation
for Longitudinal Clinical Records), a framework that incorporate
instruction-response pairs grounding to different parts of a patient's record
as a critical dimension in both instruction evaluation and tuning for
longitudinal clinical records. We develop TIMER-Bench, the first time-aware
benchmark that evaluates temporal reasoning capabilities over longitudinal
EHRs, as well as TIMER-Instruct, an instruction-tuning methodology for LLMs to
learn reasoning over time. We demonstrate that models fine-tuned with
TIMER-Instruct improve performance by 7.3% on human-generated benchmarks and
9.2% on TIMER-Bench, indicating that temporal instruction-tuning improves model
performance for reasoning over EHR.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> TIMER introduces a framework and benchmark for improving LLMs' temporal reasoning over longitudinal clinical records, enhancing performance through temporal instruction tuning.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04176v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTIMER:+Temporal+Instruction+Modeling+and+Evaluation+for+Longitudinal+Clinical+Records%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04176v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Measuring temporal effects of agent knowledge by date-controlled tool use</div>
        <div class="paper-authors">R. Patrick Xian, Qiming Cui, Stefan Bauer, Reza Abbasi-Asl</div>
        <div class="paper-affiliations">UC Berkeley, Technical University of Munich, UC San Francisco</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Temporal Knowledge Evaluation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Temporal progression is an integral part of knowledge accumulation and
update. Web search is frequently adopted as grounding for agent knowledge, yet
its inappropriate configuration affects the quality of agent responses. Here,
we construct a tool-based out-of-sample testing framework to measure the
knowledge variability of large language model (LLM) agents from distinct
date-controlled tools (DCTs). We demonstrate the temporal effects of an LLM
agent as a writing assistant, which can use web search to help complete
scientific publication abstracts. We show that temporal effects of the search
engine translates into tool-dependent agent performance but can be alleviated
with base model choice and explicit reasoning instructions such as
chain-of-thought prompting. Our results indicate that agent evaluation should
take a dynamical view and account for the temporal influence of tools and the
updates of external resources.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces a tool-based out-of-sample testing framework to measure the temporal effects of large language model (LLM) agents' knowledge variability using date-controlled tools, highlighting the impact of search engine temporal effects on agent performance and the potential mitigation through model choice and reasoning instructions.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04188v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBMeasuring+temporal+effects+of+agent+knowledge+by+date-controlled+tool+use%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04188v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Knowledge-Decoupled Synergetic Learning: An MLLM based Collaborative Approach to Few-shot Multimodal Dialogue Intention Recognition</div>
        <div class="paper-authors">Bin Chen, Yu Zhang, Hongfei Ye, Ziyi Huang, Hongyang Chen</div>
        <div class="paper-affiliations">University of Chinese Academy of Sciences, Zhejiang Lab, Zhejiang University, University of Chinese Academy of Science</div>
        <div class="paper-tag"><strong>Tag:</strong> Multimodal Large Language Models (MLLMs)</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Few-shot multimodal dialogue intention recognition is a critical challenge in
the e-commerce domainn. Previous methods have primarily enhanced model
classification capabilities through post-training techniques. However, our
analysis reveals that training for few-shot multimodal dialogue intention
recognition involves two interconnected tasks, leading to a seesaw effect in
multi-task learning. This phenomenon is attributed to knowledge interference
stemming from the superposition of weight matrix updates during the training
process. To address these challenges, we propose Knowledge-Decoupled Synergetic
Learning (KDSL), which mitigates these issues by utilizing smaller models to
transform knowledge into interpretable rules, while applying the post-training
of larger models. By facilitating collaboration between the large and small
multimodal large language models for prediction, our approach demonstrates
significant improvements. Notably, we achieve outstanding results on two real
Taobao datasets, with enhancements of 6.37\% and 6.28\% in online weighted F1
scores compared to the state-of-the-art method, thereby validating the efficacy
of our framework.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Knowledge-Decoupled Synergetic Learning (KDSL), a framework that mitigates knowledge interference in few-shot multimodal dialogue intention recognition by leveraging smaller models for rule generation and larger models for post-training, achieving significant performance improvements on e-commerce datasets.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04201v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBKnowledge-Decoupled+Synergetic+Learning:+An+MLLM+based+Collaborative+Approach+to+Few-shot+Multimodal+Dialogue+Intention+Recognition%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04201v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion</div>
        <div class="paper-authors">Ziyi Yang, Fanqi Wan, Longguang Zhong, Canbin Huang, Guosheng Liang, ...</div>
        <div class="paper-affiliations">Sun Yat-sen University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Model Fusion</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> We introduce FuseChat-3.0, a suite of large language models (LLMs) developed
by integrating the strengths of heterogeneous source LLMs into more compact
target LLMs. Our source models include the powerful Gemma-2-27B-it,
Mistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct.
For target models, we focus on three widely-used smaller
variants-Llama-3.1-8B-Instruct, Gemma-2-9B-it, and Qwen-2.5-7B-Instruct-along
with two ultra-compact options, Llama-3.2-3B-Instruct and
Llama-3.2-1B-Instruct. To leverage the diverse capabilities of these source
models, we develop a specialized data construction protocol tailored to various
tasks and domains. The FuseChat-3.0 training pipeline consists of two key
stages: (1) supervised fine-tuning (SFT) to align the target and source model
distributions, and (2) Direct Preference Optimization (DPO) to apply
preferences from multiple source LLMs to fine-tune the target model. The
resulting FuseChat-3.0 models exhibit significant performance gains across
tasks such as instruction following, general knowledge, mathematics, and
coding. As illustrated in Figure 1, using Llama-3.1-8B-Instruct as the target
model, our fusion approach achieves an average improvement of 6.8 points across
14 benchmarks. Moreover, it demonstrates remarkable gains of 37.1 points and
30.1 points on the instruction-following benchmarks AlpacaEval-2 and
Arena-Hard, respectively. Our code, models, and datasets are available at
https://github.com/SLIT-AI/FuseChat-3.0.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> FuseChat-3.0 integrates heterogeneous source LLMs into compact target models using supervised fine-tuning and Direct Preference Optimization, achieving significant performance gains across diverse tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04222v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBFuseChat-3.0:+Preference+Optimization+Meets+Heterogeneous+Model+Fusion%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04222v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Tgea: An error-annotated dataset and benchmark tasks for text generation from pretrained language models</div>
        <div class="paper-authors">Jie He, Bo Peng, Yi Liao, Qun Liu, Deyi Xiong</div>
        <div class="paper-affiliations">Tianjin University, Huawei Noah’s Ark Lab</div>
        <div class="paper-tag"><strong>Tag:</strong> Error Detection in Pretrained Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> In order to deeply understand the capability of pretrained language models in
text generation and conduct a diagnostic evaluation, we propose TGEA, an
error-annotated dataset with multiple benchmark tasks for text generation from
pretrained language models (PLMs). We use carefully selected prompt words to
guide GPT-2 to generate candidate sentences, from which we select 47K for error
annotation. Crowdsourced workers manually check each of these sentences and
detect 12k erroneous sentences. We create an error taxonomy to cover 24 types
of errors occurring in these erroneous sentences according to the nature of
errors with respect to linguistics and knowledge (eg, common sense). For each
erroneous span in PLM-generated sentences, we also detect another span that is
closely associated with it. Each error is hence manually labeled with
comprehensive annotations, including the span of the error, the associated
span, minimal correction to the error, the type of the error, and rationale
behind the error. Apart from the fully annotated dataset, we also present a
detailed description of the data collection procedure, statistics and analysis
of the dataset. This is the first dataset with comprehensive annotations for
PLM-generated texts, which facilitates the diagnostic evaluation of PLM-based
text generation. Furthermore, we use TGEA as a benchmark dataset and propose a
series of automatic diagnosis tasks, including error detection, error type
classification, associated span detection, error rationale generation, to
further promote future study on the automatic error detection and correction on
texts generated by pretrained language models.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> TGEA is an error-annotated dataset with multiple benchmark tasks for text generation from pretrained language models, providing comprehensive annotations for diagnostic evaluation and automatic error detection and correction.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04232v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTgea:+An+error-annotated+dataset+and+benchmark+tasks+for+text+generation+from+pretrained+language+models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04232v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">DiffPO: Diffusion-styled Preference Optimization for Efficient Inference-Time Alignment of Large Language Models</div>
        <div class="paper-authors">Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Joey Tianyi Zhou, ...</div>
        <div class="paper-affiliations">A*STAR Centre for Frontier AI Research, Zhejiang University, Peking University, University of Washington, SUTD</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Inference-Time Alignment</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Inference-time alignment provides an efficient alternative for aligning LLMs
with humans. However, these approaches still face challenges, such as limited
scalability due to policy-specific value functions and latency during the
inference phase. In this paper, we propose a novel approach, Diffusion-styled
Preference Optimization (\model), which provides an efficient and
policy-agnostic solution for aligning LLMs with humans. By directly performing
alignment at sentence level, \model~avoids the time latency associated with
token-level generation. Designed as a plug-and-play module, \model~can be
seamlessly integrated with various base models to enhance their alignment.
Extensive experiments on AlpacaEval 2, MT-bench, and HH-RLHF demonstrate that
\model~achieves superior alignment performance across various settings,
achieving a favorable trade-off between alignment quality and inference-time
latency. Furthermore, \model~demonstrates model-agnostic scalability,
significantly improving the performance of large models such as Llama-3-70B.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> DiffPO introduces a diffusion-styled preference optimization method for efficient, model-agnostic inference-time alignment of large language models, achieving superior performance with reduced latency.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04240v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDiffPO:+Diffusion-styled+Preference+Optimization+for+Efficient+Inference-Time+Alignment+of+Large+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04240v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">VirtualXAI: A User-Centric Framework for Explainability Assessment Leveraging GPT-Generated Personas</div>
        <div class="paper-authors">Georgios Makridis, Vasileios Koukos, Georgios Fatouros, Dimosthenis Kyriazis</div>
        <div class="paper-affiliations">University of Piraeus</div>
        <div class="paper-tag"><strong>Tag:</strong> Explainable AI (XAI) Evaluation Frameworks</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> In today's data-driven era, computational systems generate vast amounts of
data that drive the digital transformation of industries, where Artificial
Intelligence (AI) plays a key role. Currently, the demand for eXplainable AI
(XAI) has increased to enhance the interpretability, transparency, and
trustworthiness of AI models. However, evaluating XAI methods remains
challenging: existing evaluation frameworks typically focus on quantitative
properties such as fidelity, consistency, and stability without taking into
account qualitative characteristics such as satisfaction and interpretability.
In addition, practitioners face a lack of guidance in selecting appropriate
datasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.
To address these gaps, we propose a framework that integrates quantitative
benchmarking with qualitative user assessments through virtual personas based
on the "Anthology" of backstories of the Large Language Model (LLM). Our
framework also incorporates a content-based recommender system that leverages
dataset-specific characteristics to match new input data with a repository of
benchmarked datasets. This yields an estimated XAI score and provides tailored
recommendations for both the optimal AI model and the XAI method for a given
scenario.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> VirtualXAI introduces a user-centric framework combining quantitative benchmarking and qualitative assessments using GPT-generated personas to enhance the interpretability and trustworthiness of AI models.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04261v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBVirtualXAI:+A+User-Centric+Framework+for+Explainability+Assessment+Leveraging+GPT-Generated+Personas%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04261v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Guidelines for Applying RL and MARL in Cybersecurity Applications</div>
        <div class="paper-authors">Vasilios Mavroudis, Gregory Palmer, Sara Farmer, Kez Smithson Whitehead, David Foster, ...</div>
        <div class="paper-affiliations">BMT Group, Alan Turing Institute, Montvieux, Frazer-Nash Consultancy, BAE Systems, ...</div>
        <div class="paper-tag"><strong>Tag:</strong> Multi-Agent Reinforcement Learning in Cybersecurity</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL)
have emerged as promising methodologies for addressing challenges in automated
cyber defence (ACD). These techniques offer adaptive decision-making
capabilities in high-dimensional, adversarial environments. This report
provides a structured set of guidelines for cybersecurity professionals and
researchers to assess the suitability of RL and MARL for specific use cases,
considering factors such as explainability, exploration needs, and the
complexity of multi-agent coordination. It also discusses key algorithmic
approaches, implementation challenges, and real-world constraints, such as data
scarcity and adversarial interference. The report further outlines open
research questions, including policy optimality, agent cooperation levels, and
the integration of MARL systems into operational cybersecurity frameworks. By
bridging theoretical advancements and practical deployment, these guidelines
aim to enhance the effectiveness of AI-driven cyber defence strategies.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper provides guidelines for applying Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL) in cybersecurity, focusing on adaptive decision-making, multi-agent coordination, and real-world challenges like data scarcity and adversarial interference.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04262v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBGuidelines+for+Applying+RL+and+MARL+in+Cybersecurity+Applications%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04262v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">On Fact and Frequency: LLM Responses to Misinformation Expressed with Uncertainty</div>
        <div class="paper-authors">Yana van de Sande, Gunes Açar, Thabo van Woudenberg, Martha Larson</div>
        <div class="paper-affiliations">Radboud University, iHub</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Uncertainty Handling</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> We study LLM judgments of misinformation expressed with uncertainty. Our
experiments study the response of three widely used LLMs (GPT-4o, LlaMA3,
DeepSeek-v2) to misinformation propositions that have been verified false and
then are transformed into uncertain statements according to an uncertainty
typology. Our results show that after transformation, LLMs change their
factchecking classification from false to not-false in 25% of the cases.
Analysis reveals that the change cannot be explained by predictors to which
humans are expected to be sensitive, i.e., modality, linguistic cues, or
argumentation strategy. The exception is doxastic transformations, which use
linguistic cue phrases such as "It is believed ...".To gain further insight, we
prompt the LLM to make another judgment about the transformed misinformation
statements that is not related to truth value. Specifically, we study LLM
estimates of the frequency with which people make the uncertain statement. We
find a small but significant correlation between judgment of fact and
estimation of frequency.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> LLMs change their fact-checking classification from false to not-false in 25% of cases when misinformation is expressed with uncertainty, with a small but significant correlation between fact judgment and frequency estimation.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04271v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBOn+Fact+and+Frequency:+LLM+Responses+to+Misinformation+Expressed+with+Uncertainty%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04271v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Dual-Class Prompt Generation: Enhancing Indonesian Gender-Based Hate Speech Detection through Data Augmentation</div>
        <div class="paper-authors">Muhammad Amien Ibrahim, Faisal, Tora Sangputra Yopie Winarto, Zefanya Delvin Sulistiya</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Data Augmentation for Hate Speech Detection</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Detecting gender-based hate speech in Indonesian social media remains
challenging due to limited labeled datasets. While binary hate speech
classification has advanced, a more granular category like gender-targeted hate
speech is understudied because of class imbalance issues. This paper addresses
this gap by comparing three data augmentation techniques for Indonesian
gender-based hate speech detection. We evaluate backtranslation, single-class
prompt generation (using only hate speech examples), and our proposed
dual-class prompt generation (using both hate speech and non-hate speech
examples). Experiments show all augmentation methods improve classification
performance, with our dual-class approach achieving the best results (88.5%
accuracy, 88.1% F1-score using Random Forest). Semantic similarity analysis
reveals dual-class prompt generation produces the most novel content, while
T-SNE visualizations confirm these samples occupy distinct feature space
regions while maintaining class characteristics. Our findings suggest that
incorporating examples from both classes helps language models generate more
diverse yet representative samples, effectively addressing limited data
challenges in specialized hate speech detection.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Dual-class prompt generation, using both hate speech and non-hate speech examples, outperforms other data augmentation techniques in enhancing Indonesian gender-based hate speech detection.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04279v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDual-Class+Prompt+Generation:+Enhancing+Indonesian+Gender-Based+Hate+Speech+Detection+through+Data+Augmentation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04279v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">MathMistake Checker: A Comprehensive Demonstration for Step-by-Step Math Problem Mistake Finding by Prompt-Guided LLMs</div>
        <div class="paper-authors">Tianyang Zhang, Zhuoxuan Jiang, Haotian Zhang, Lin Lin, Shaohua Zhang</div>
        <div class="paper-affiliations">Learnable.ai, Shanghai Business School, UCloud Technology Co. Ltd.</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Chain-of-Thought Prompting</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> We propose a novel system, MathMistake Checker, designed to automate
step-by-step mistake finding in mathematical problems with lengthy answers
through a two-stage process. The system aims to simplify grading, increase
efficiency, and enhance learning experiences from a pedagogical perspective. It
integrates advanced technologies, including computer vision and the
chain-of-thought capabilities of the latest large language models (LLMs). Our
system supports open-ended grading without reference answers and promotes
personalized learning by providing targeted feedback. We demonstrate its
effectiveness across various types of math problems, such as calculation and
word problems.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> MathMistake Checker is a system that automates step-by-step mistake finding in mathematical problems using OCR and LLMs, enhancing grading efficiency and personalized learning.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04291v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBMathMistake+Checker:+A+Comprehensive+Demonstration+for+Step-by-Step+Math+Problem+Mistake+Finding+by+Prompt-Guided+LLMs%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04291v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Mapping AI Benchmark Data to Quantitative Risk Estimates Through Expert Elicitation</div>
        <div class="paper-authors">Malcolm Murray, Henry Papadatos, Otter Quarks, Pierre-François Gimenez, Simeon Campos</div>
        <div class="paper-affiliations">Univ. Rennes, SaferAI</div>
        <div class="paper-tag"><strong>Tag:</strong> AI Risk Modeling</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The literature and multiple experts point to many potential risks from large
language models (LLMs), but there are still very few direct measurements of the
actual harms posed. AI risk assessment has so far focused on measuring the
models' capabilities, but the capabilities of models are only indicators of
risk, not measures of risk. Better modeling and quantification of AI risk
scenarios can help bridge this disconnect and link the capabilities of LLMs to
tangible real-world harm. This paper makes an early contribution to this field
by demonstrating how existing AI benchmarks can be used to facilitate the
creation of risk estimates. We describe the results of a pilot study in which
experts use information from Cybench, an AI benchmark, to generate probability
estimates. We show that the methodology seems promising for this purpose, while
noting improvements that can be made to further strengthen its application in
quantitative AI risk assessment.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper demonstrates how AI benchmark data can be mapped to quantitative risk estimates through expert elicitation, bridging the gap between model capabilities and real-world harms.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04299v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBMapping+AI+Benchmark+Data+to+Quantitative+Risk+Estimates+Through+Expert+Elicitation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04299v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Computational Law: Datasets, Benchmarks, and Ontologies</div>
        <div class="paper-authors">Dilek Küçük, Fazli Can</div>
        <div class="paper-affiliations">Bilkent University, TÜBİTAK Marmara Research Center</div>
        <div class="paper-tag"><strong>Tag:</strong> Legal Text Classification with LLMs</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Recent developments in computer science and artificial intelligence have also
contributed to the legal domain, as revealed by the number and range of related
publications and applications. Machine and deep learning models require
considerable amount of domain-specific data for training and comparison
purposes, in order to attain high-performance in the legal domain.
Additionally, semantic resources such as ontologies are valuable for building
large-scale computational legal systems, in addition to ensuring
interoperability of such systems. Considering these aspects, we present an
up-to-date review of the literature on datasets, benchmarks, and ontologies
proposed for computational law. We believe that this comprehensive and recent
review will help researchers and practitioners when developing and testing
approaches and systems for computational law.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper provides a comprehensive review of datasets, benchmarks, and ontologies essential for advancing computational law, aiding researchers and practitioners in developing AI-based legal systems.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04305v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBComputational+Law:+Datasets%2C+Benchmarks%2C+and+Ontologies%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04305v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Solving Word-Sense Disambiguation and Word-Sense Induction with Dictionary Examples</div>
        <div class="paper-authors">Tadej Škvorc, Marko Robnik-Šikonja</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM for Word-Sense Disambiguation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Many less-resourced languages struggle with a lack of large, task-specific
datasets that are required for solving relevant tasks with modern
transformer-based large language models (LLMs). On the other hand, many
linguistic resources, such as dictionaries, are rarely used in this context
despite their large information contents. We show how LLMs can be used to
extend existing language resources in less-resourced languages for two
important tasks: word-sense disambiguation (WSD) and word-sense induction
(WSI). We approach the two tasks through the related but much more accessible
word-in-context (WiC) task where, given a pair of sentences and a target word,
a classification model is tasked with predicting whether the sense of a given
word differs between sentences. We demonstrate that a well-trained model for
this task can distinguish between different word senses and can be adapted to
solve the WSD and WSI tasks. The advantage of using the WiC task, instead of
directly predicting senses, is that the WiC task does not need pre-constructed
sense inventories with a sufficient number of examples for each sense, which
are rarely available in less-resourced languages. We show that sentence pairs
for the WiC task can be successfully generated from dictionary examples using
LLMs. The resulting prediction models outperform existing models on WiC, WSD,
and WSI tasks. We demonstrate our methodology on the Slovene language, where a
monolingual dictionary is available, but word-sense resources are tiny.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper proposes a novel methodology using LLMs to extend dictionary examples for solving Word-Sense Disambiguation (WSD) and Word-Sense Induction (WSI) tasks through the Word-in-Context (WiC) task, demonstrating improved performance on less-resourced languages like Slovene.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04328v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBSolving+Word-Sense+Disambiguation+and+Word-Sense+Induction+with+Dictionary+Examples%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04328v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Adding Alignment Control to Language Models</div>
        <div class="paper-authors">Wenhong Zhu, Weinan Zhang, Rui Wang</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Alignment Control</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Post-training alignment has increasingly become a crucial factor in enhancing
the usability of language models (LMs). However, the strength of alignment
varies depending on individual preferences. This paper proposes a method to
incorporate alignment control into a single model, referred to as CLM. This
approach adds one identity layer preceding the initial layers and performs
preference learning only on this layer to map unaligned input token embeddings
into the aligned space. Experimental results demonstrate that this efficient
fine-tuning method performs comparable to full fine-tuning. During inference,
the input embeddings are processed through the aligned and unaligned layers,
which are then merged through the interpolation coefficient. By controlling
this parameter, the alignment exhibits a clear interpolation and extrapolation
phenomenon.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces CLM, an alignment-controllable language model that adds an identity layer for preference learning, enabling dynamic alignment control via an interpolation coefficient during inference.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04346v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAdding+Alignment+Control+to+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04346v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Layer-Specific Scaling of Positional Encodings for Superior Long-Context Modeling</div>
        <div class="paper-authors">Zhenghua Wang, Yiran Ding, Changze Lv, Zhibo Xu, Tianlong Li, ...</div>
        <div class="paper-affiliations">Fudan University, Westlake University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Position Embedding</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Although large language models (LLMs) have achieved significant progress in
handling long-context inputs, they still suffer from the ``lost-in-the-middle''
problem, where crucial information in the middle of the context is often
underrepresented or lost. Our extensive experiments reveal that this issue may
arise from the rapid long-term decay in Rotary Position Embedding (RoPE). To
address this problem, we propose a layer-specific positional encoding scaling
method that assigns distinct scaling factors to each layer, slowing down the
decay rate caused by RoPE to make the model pay more attention to the middle
context. A specially designed genetic algorithm is employed to efficiently
select the optimal scaling factors for each layer by incorporating Bezier
curves to reduce the search space. Through comprehensive experimentation, we
demonstrate that our method significantly alleviates the ``lost-in-the-middle''
problem. Our approach results in an average accuracy improvement of up to 20%
on the Key-Value Retrieval dataset. Furthermore, we show that layer-specific
interpolation, as opposed to uniform interpolation across all layers, enhances
the model's extrapolation capabilities when combined with PI and Dynamic-NTK
positional encoding schemes.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper proposes a layer-specific positional encoding scaling method using a genetic algorithm constrained by Bézier curves to mitigate the "lost-in-the-middle" problem in long-context LLMs, improving accuracy by up to 20%.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04355v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLayer-Specific+Scaling+of+Positional+Encodings+for+Superior+Long-Context+Modeling%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04355v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Exploring the Multilingual NLG Evaluation Abilities of LLM-Based Evaluators</div>
        <div class="paper-authors">Jiayi Chang, Mingqi Gao, Xinyu Hu, Xiaojun Wan</div>
        <div class="paper-affiliations">Communication University of China, Peking University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Multilingual Evaluation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Previous research has shown that LLMs have potential in multilingual NLG
evaluation tasks. However, existing research has not fully explored the
differences in the evaluation capabilities of LLMs across different languages.
To this end, this study provides a comprehensive analysis of the multilingual
evaluation performance of 10 recent LLMs, spanning high-resource and
low-resource languages through correlation analysis, perturbation attacks, and
fine-tuning. We found that 1) excluding the reference answer from the prompt
and using large-parameter LLM-based evaluators leads to better performance
across various languages; 2) most LLM-based evaluators show a higher
correlation with human judgments in high-resource languages than in
low-resource languages; 3) in the languages where they are most sensitive to
such attacks, they also tend to exhibit the highest correlation with human
judgments; and 4) fine-tuning with data from a particular language yields a
broadly consistent enhancement in the model's evaluation performance across
diverse languages. Our findings highlight the imbalance in LLMs'evaluation
capabilities across different languages and suggest that low-resource language
scenarios deserve more attention.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This study comprehensively analyzes the multilingual evaluation capabilities of 10 LLMs, revealing performance disparities between high-resource and low-resource languages and suggesting improvements through fine-tuning and prompt design.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04360v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBExploring+the+Multilingual+NLG+Evaluation+Abilities+of+LLM-Based+Evaluators%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04360v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Lost in Literalism: How Supervised Training Shapes Translationese in LLMs</div>
        <div class="paper-authors">Yafu Li, Ronghao Zhang, Zhilin Wang, Huajian Zhang, Leyang Cui, ...</div>
        <div class="paper-affiliations">Westlake University, Northeastern University, Zhejiang University, Shanghai AI Laboratory</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Translationese Mitigation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large language models (LLMs) have achieved remarkable success in machine
translation, demonstrating impressive performance across diverse languages.
However, translationese, characterized by overly literal and unnatural
translations, remains a persistent challenge in LLM-based translation systems.
Despite their pre-training on vast corpora of natural utterances, LLMs exhibit
translationese errors and generate unexpected unnatural translations, stemming
from biases introduced during supervised fine-tuning (SFT). In this work, we
systematically evaluate the prevalence of translationese in LLM-generated
translations and investigate its roots during supervised training. We introduce
methods to mitigate these biases, including polishing golden references and
filtering unnatural training instances. Empirical evaluations demonstrate that
these approaches significantly reduce translationese while improving
translation naturalness, validated by human evaluations and automatic metrics.
Our findings highlight the need for training-aware adjustments to optimize LLM
translation outputs, paving the way for more fluent and
target-language-consistent translations. We release the data and code at
https://github.com/yafuly/LLM_Translationese.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Supervised fine-tuning biases in large language models lead to translationese, but refining training references and filtering unnatural instances can significantly improve translation naturalness.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04369v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLost+in+Literalism:+How+Supervised+Training+Shapes+Translationese+in+LLMs%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04369v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Assumed Identities: Quantifying Gender Bias in Machine Translation of Ambiguous Occupational Terms</div>
        <div class="paper-authors">Orfeas Menis Mastromichalakis, Giorgos Filandrianos, Maria Symeonaki, Giorgos Stamou</div>
        <div class="paper-affiliations">National Technical University of Athens, Panteion University of Social and Political Sciences</div>
        <div class="paper-tag"><strong>Tag:</strong> Gender Bias in Machine Translation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Machine Translation (MT) systems frequently encounter ambiguous scenarios
where they must assign gender to certain occupations when translating without
explicit guidance or contextual cues. While individual translations in such
cases may not be inherently biased, systematic patterns-such as the repeated
association of certain professions with specific genders-can emerge, reflecting
and perpetuating societal stereotypes. This ambiguity challenges traditional
instance-level single-answer evaluation approaches, as no single gold standard
translation exists. To address this, we propose an approach that evaluates
gender bias through aggregated model responses. Specifically, we introduce a
methodology to detect gender imbalances between source texts and translations,
a benchmarking dataset with ambiguous English inputs, and probability-based
metrics to quantify a model's divergence from normative standards or reference
distributions.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper proposes a methodology to quantify gender bias in machine translation systems by analyzing aggregated model responses to ambiguous occupational terms, introducing a benchmarking dataset and probability-based metrics to evaluate deviations from normative gender representations.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04372v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAssumed+Identities:+Quantifying+Gender+Bias+in+Machine+Translation+of+Ambiguous+Occupational+Terms%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04372v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks</div>
        <div class="paper-authors">Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, ...</div>
        <div class="paper-affiliations">NVIDIA</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Feedback Mechanisms</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Inference-Time Scaling has been critical to the success of recent models such
as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for
inference-time scaling require tasks to have answers that can be verified,
limiting their application to domains such as math, coding and logical
reasoning. We take inspiration from how humans make first attempts, ask for
detailed feedback from others and make improvements based on such feedback
across a wide spectrum of open-ended endeavors. To this end, we collect data
for and train dedicated Feedback and Edit Models that are capable of performing
inference-time scaling for open-ended general-domain tasks. In our setup, one
model generates an initial response, which are given feedback by a second
model, that are then used by a third model to edit the response. We show that
performance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo
can be boosted by scaling the number of initial response drafts, effective
feedback and edited responses. When scaled optimally, our setup based on 70B
models from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7
as of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and
DeepSeek R1 with 92.3.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Dedicated Feedback and Edit Models enable inference-time scaling for open-ended general-domain tasks, achieving state-of-the-art performance on Arena Hard with a score of 92.7.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04378v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDedicated+Feedback+and+Edit+Models+Empower+Inference-Time+Scaling+for+Open-Ended+General-Domain+Tasks%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04378v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge</div>
        <div class="paper-authors">Cheng-Han Chiang, Hung-yi Lee, Michal Lukasik</div>
        <div class="paper-affiliations">National Taiwan University, Google Research</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Fine-tuning for Numerical Prediction</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The LLM-as-a-judge paradigm uses large language models (LLMs) for automated
text evaluation, where a numerical assessment is assigned by an LLM to the
input text following scoring rubrics. Existing methods for LLM-as-a-judge use
cross-entropy (CE) loss for fine-tuning, which neglects the numeric nature of
score prediction. Recent work addresses numerical prediction limitations of LLM
fine-tuning through regression-aware fine-tuning, which, however, does not
consider chain-of-thought (CoT) reasoning for score prediction. In this paper,
we introduce TRACT (Two-stage Regression-Aware fine-tuning with CoT), a method
combining CoT reasoning with regression-aware training. TRACT consists of two
stages: first, seed LLM is fine-tuned to generate CoTs, which serve as
supervision for the second stage fine-tuning. The training objective of TRACT
combines the CE loss for learning the CoT reasoning capabilities, and the
regression-aware loss for the score prediction. Experiments across four
LLM-as-a-judge datasets and two LLMs show that TRACT significantly outperforms
existing methods. Extensive ablation studies validate the importance of each
component in TRACT.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> TRACT introduces a two-stage fine-tuning method combining chain-of-thought reasoning with regression-aware training to improve LLM-as-a-judge performance.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04381v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTRACT:+Regression-Aware+Fine-tuning+Meets+Chain-of-Thought+Reasoning+for+LLM-as-a-Judge%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04381v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">More Documents, Same Length: Isolating the Challenge of Multiple Documents in RAG</div>
        <div class="paper-authors">Shahar Levy, Nir Mazor, Lihi Shalmon, Michael Hassid, Gabriel Stanovsky</div>
        <div class="paper-affiliations">The Hebrew University of Jerusalem</div>
        <div class="paper-tag"><strong>Tag:</strong> Multi-Document Processing in RAG</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Retrieval-augmented generation (RAG) provides LLMs with relevant documents.
Although previous studies noted that retrieving many documents can degrade
performance, they did not isolate how the quantity of documents affects
performance while controlling for context length. We evaluate various language
models on custom datasets derived from a multi-hop QA task. We keep the context
length and position of relevant information constant while varying the number
of documents, and find that increasing the document count in RAG settings poses
significant challenges for LLMs. Additionally, our results indicate that
processing multiple documents is a separate challenge from handling long
contexts. We also make the datasets and code available:
https://github.com/shaharl6000/MoreDocsSameLen .</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Increasing the number of retrieved documents in retrieval-augmented generation (RAG) settings, while keeping context length constant, significantly challenges LLMs, indicating that processing multiple documents is a separate issue from handling long contexts.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04388v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBMore+Documents%2C+Same+Length:+Isolating+the+Challenge+of+Multiple+Documents+in+RAG%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04388v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management</div>
        <div class="paper-authors">Junyuan Mao, Fanci Meng, Yifan Duan, Miao Yu, Xiaojun Jia, ...</div>
        <div class="paper-affiliations">University of Science and Technology of China, Nanyang Technological University, Squirrel Ai Learning, The Hong Kong University of Science and Technology (Guangzhou)</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM-based Multi-agent System Security</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Model based multi-agent systems are revolutionizing autonomous
communication and collaboration, yet they remain vulnerable to security threats
like unauthorized access and data breaches. To address this, we introduce
AgentSafe, a novel framework that enhances MAS security through hierarchical
information management and memory protection. AgentSafe classifies information
by security levels, restricting sensitive data access to authorized agents.
AgentSafe incorporates two components: ThreatSieve, which secures communication
by verifying information authority and preventing impersonation, and
HierarCache, an adaptive memory management system that defends against
unauthorized access and malicious poisoning, representing the first systematic
defense for agent memory. Experiments across various LLMs show that AgentSafe
significantly boosts system resilience, achieving defense success rates above
80% under adversarial conditions. Additionally, AgentSafe demonstrates
scalability, maintaining robust performance as agent numbers and information
complexity grow. Results underscore effectiveness of AgentSafe in securing MAS
and its potential for real-world application.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> AgentSafe is a hierarchical data management framework that enhances security in LLM-based multi-agent systems by classifying information by security levels and protecting against unauthorized access and memory attacks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04392v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAgentSafe:+Safeguarding+Large+Language+Model-based+Multi-agent+Systems+via+Hierarchical+Data+Management%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04392v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Shaping Shared Languages: Human and Large Language Models' Inductive Biases in Emergent Communication</div>
        <div class="paper-authors">Tom Kouwenhoven, Max Peeperkorn, Roy de Kleijn, Tessa Verhoef</div>
        <div class="paper-affiliations">Leiden University, University of Kent</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Inductive Biases in Language Evolution</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Languages are shaped by the inductive biases of their users. Using a
classical referential game, we investigate how artificial languages evolve when
optimised for inductive biases in humans and large language models (LLMs) via
Human-Human, LLM-LLM and Human-LLM experiments. We show that referentially
grounded vocabularies emerge that enable reliable communication in all
conditions, even when humans and LLMs collaborate. Comparisons between
conditions reveal that languages optimised for LLMs subtly differ from those
optimised for humans. Interestingly, interactions between humans and LLMs
alleviate these differences and result in vocabularies which are more
human-like than LLM-like. These findings advance our understanding of how
inductive biases in LLMs play a role in the dynamic nature of human language
and contribute to maintaining alignment in human and machine communication. In
particular, our work underscores the need to think of new methods that include
human interaction in the training processes of LLMs, and shows that using
communicative success as a reward signal can be a fruitful, novel direction.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Emergent languages from Human-LLM interactions are more human-like, showing that LLMs adapt to human inductive biases, which is crucial for maintaining alignment in human-machine communication.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04395v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBShaping+Shared+Languages:+Human+and+Large+Language+Models%27+Inductive+Biases+in+Emergent+Communication%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04395v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models</div>
        <div class="paper-authors">Xinyi He, Yihao Liu, Mengyu Zhou, Yeye He, Haoyu Dong, ...</div>
        <div class="paper-affiliations">Xi'an Jiaotong University, Microsoft Research, Peking University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Table Structure Understanding</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Tabular data are crucial in many fields and their understanding by large
language models (LLMs) under high parameter efficiency paradigm is important.
However, directly applying parameter-efficient fine-tuning (PEFT) techniques to
tabular tasks presents significant challenges, particularly in terms of better
table serialization and the representation of two-dimensional structured
information within a one-dimensional sequence. To address this, we propose
TableLoRA, a module designed to improve LLMs' understanding of table structure
during PEFT. It incorporates special tokens for serializing tables with special
token encoder and uses 2D LoRA to encode low-rank information on cell
positions. Experiments on four tabular-related datasets demonstrate that
TableLoRA consistently outperforms vanilla LoRA and surpasses various table
encoding methods tested in control experiments. These findings reveal that
TableLoRA, as a table-specific LoRA, enhances the ability of LLMs to process
tabular data effectively, especially in low-parameter settings, demonstrating
its potential as a robust solution for handling table-related tasks.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> TableLoRA enhances LLMs' understanding of tabular data by introducing a special tokens encoder and 2D LoRA, outperforming vanilla LoRA in table-related tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04396v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTableLoRA:+Low-rank+Adaptation+on+Table+Structure+Understanding+for+Large+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04396v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model</div>
        <div class="paper-authors">Sanjib Narzary, Bihung Brahma, Haradip Mahilary, Mahananda Brahma, Bidisha Som, ...</div>
        <div class="paper-affiliations">Central Institute of Technology Kokrajhar, IIT Guwahati</div>
        <div class="paper-tag"><strong>Tag:</strong> Zero-Shot Cross-Lingual Transfer</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical
tasks for Natural Language Processing (NLP), yet their availability for
low-resource languages (LRLs) like Bodo remains limited. This article presents
a comparative empirical study investigating the effectiveness of Google's
Gemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer
of POS and NER tagging to Bodo. We explore two distinct methodologies: (1)
direct translation of English sentences to Bodo followed by tag transfer, and
(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both
methods leverage the machine translation and cross-lingual understanding
capabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and
NER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the
capabilities and limitations of each approach, demonstrating that while both
methods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits
superior performance, particularly for NER. We provide a detailed analysis of
the results, highlighting the impact of translation quality, grammatical
divergences, and the inherent challenges of zero-shot cross-lingual transfer.
The article concludes by discussing future research directions, emphasizing the
need for hybrid approaches, few-shot fine-tuning, and the development of
dedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for
this low-resource language.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The study evaluates zero-shot cross-lingual transfer for Bodo POS and NER tagging using Gemini 2.0 Flash Thinking, finding prompt-based transfer superior and highlighting the need for advanced techniques and resources for low-resource languages.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04405v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBComparative+Study+of+Zero-Shot+Cross-Lingual+Transfer+for+Bodo+POS+and+NER+Tagging+Using+Gemini+2.0+Flash+Thinking+Experimental+Model%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04405v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search</div>
        <div class="paper-authors">Kou Misaki, Yuichi Inoue, Yuki Imajuku, So Kuroki, Taishi Nakamura, ...</div>
        <div class="paper-affiliations">Sakana AI</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Inference-Time Optimization</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Recent advances demonstrate that increasing inference-time computation can
significantly boost the reasoning capabilities of large language models (LLMs).
Although repeated sampling (i.e., generating multiple candidate outputs) is a
highly effective strategy, it does not leverage external feedback signals for
refinement, which are often available in tasks like coding. In this work, we
propose $\textit{Adaptive Branching Monte Carlo Tree Search (AB-MCTS)}$, a
novel inference-time framework that generalizes repeated sampling with
principled multi-turn exploration and exploitation. At each node in the search
tree, AB-MCTS dynamically decides whether to "go wider" by expanding new
candidate responses or "go deeper" by revisiting existing ones based on
external feedback signals. We evaluate our method on complex coding and
engineering tasks using frontier models. Empirical results show that AB-MCTS
consistently outperforms both repeated sampling and standard MCTS, underscoring
the importance of combining the response diversity of LLMs with multi-turn
solution refinement for effective inference-time scaling.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Adaptive Branching Monte Carlo Tree Search (AB-MCTS), a novel inference-time framework that dynamically balances exploration and exploitation in LLMs by deciding whether to generate new candidate responses or refine existing ones based on external feedback, outperforming repeated sampling and standard MCTS on complex tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.04412v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBWider+or+Deeper?+Scaling+LLM+Inference-Time+Compute+with+Adaptive+Branching+Tree+Search%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.04412v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br>
  </div>

  <div class="footer">
    <p>To unsubscribe, remove your email in your Github Action setting.</p>
    <p>To have a full reading experience, <a href='https://xiangsam.github.io/arxiv-daily/'>visit this page</a> in a modern brower.</p>
    <p>&copy; 2023 Research Digest. All rights reserved.</p>
  </div>
</div>

<!-- Toast 提示条 -->
<div class="toast" id="toast">Added to favorites!</div>

<!-- 模态框 -->
<div class="modal" id="modal">
  <div class="modal-content">
    <div class="modal-actions">
      <button class="modal-button" onclick="openInNewTab()" title="Open in new tab">
        <i class="fas fa-external-link-alt"></i>
      </button>
      <button class="modal-button close" onclick="closeModal()" title="Close">
        <i class="fas fa-times"></i>
      </button>
    </div>
    <iframe class="modal-iframe" id="modal-iframe" src=""></iframe>
  </div>
</div>

<a href="#" class="back-to-top">↑</a>

<script>
  // 检测是否在浏览器中正常加载
  function isNormalBrowserLoad() {
    // 检查是否可以执行JavaScript
    if (typeof window!== 'undefined' && 'location' in window) {
      return true;
    }
    return false;
  }

  // 隐藏提示条
  if (isNormalBrowserLoad()) {
    const prompt = document.getElementById('browser-prompt');
    prompt.style.display = 'none'; // 隐藏提示条
  }
  
  // 动态加载效果
  document.addEventListener('DOMContentLoaded', function () {
    const paperBlocks = document.querySelectorAll('.paper-block');
    paperBlocks.forEach((block, index) => {
      setTimeout(() => {
        block.classList.add('visible');
      }, index * 200);
    });
  });

  // 回到顶部按钮
  const backToTopButton = document.querySelector('.back-to-top');
  backToTopButton.addEventListener('click', (e) => {
    e.preventDefault();
    window.scrollTo({ top: 0, behavior: 'smooth' });
  });

  // 心形按钮点击提示
  function toggleHeart(button) {
    button.classList.toggle('active');
    showToast('Added to favorites!');
  }

  // 显示 Toast 提示
  function showToast(message) {
    const toast = document.getElementById('toast');
    toast.textContent = message;
    toast.classList.add('visible');
    setTimeout(() => {
      toast.classList.remove('visible');
    }, 3000); // 3 秒后消失
  }
  
  // 打开模态框
  function openModal(url) {
    const modal = document.getElementById('modal');
    const iframe = document.getElementById('modal-iframe');
    iframe.src = url;
    modal.classList.add('visible');
  }

  // 关闭模态框
  function closeModal() {
    const modal = document.getElementById('modal');
    const iframe = document.getElementById('modal-iframe');
    iframe.src = ''; // 清空 iframe 内容
    modal.classList.remove('visible');
  }

  // 在新标签页打开
  function openInNewTab() {
    const iframe = document.getElementById('modal-iframe');
    const url = iframe.src;
    if (url) {
      window.open(url, '_blank');
    }
  }
</script>

</body>
</html>
