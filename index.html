
<!DOCTYPE HTML>
<html>
<head>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
  <style>
    body {
      font-family: 'Roboto', sans-serif;
      background-color: #f5f5f5;
      margin: 0;
      padding: 20px;
      color: #333;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      background-color: #fff;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      padding: 24px;
      position: relative;
    }
    .header {
      text-align: center;
      margin-bottom: 32px;
    }
    .header h1 {
      font-size: 32px;
      font-weight: 700;
      color: #2c3e50;
      margin-bottom: 8px;
    }
    .header p {
      font-size: 16px;
      color: #666;
    }
    .paper-block {
      margin-bottom: 24px;
      padding: 16px;
      border-radius: 8px;
      background-color: #f9f9f9;
      border: 1px solid #ddd;
      opacity: 0;
      transform: translateY(20px);
      transition: opacity 0.6s ease, transform 0.6s ease;
    }
    .paper-block.visible {
      opacity: 1;
      transform: translateY(0);
    }
    .paper-title {
      font-size: 24px;
      font-weight: 700;
      color: #2c3e50;
      margin-bottom: 8px;
    }
    .paper-authors {
      font-size: 14px;
      color: #666;
      margin-bottom: 8px;
    }
    .paper-affiliations {
      font-size: 12px;
      color: #888;
      font-style: italic;
      margin-bottom: 8px;
    }
    .paper-tag {
      font-size: 14px;
      color: #333;
      margin-bottom: 8px;
    }
    .paper-score {
      font-size: 14px;
      color: #333;
      margin-bottom: 8px;
    }
    .paper-abstract {
      font-size: 14px;
      color: #444;
      line-height: 1.6;
      margin-bottom: 16px;
    }
    .paper-tldr {
      font-size: 14px;
      color: #444;
      line-height: 1.6;
      margin-bottom: 16px;
    }
    .paper-actions {
      display: flex;
      gap: 8px;
      align-items: center;
    }
    .paper-actions a {
      text-decoration: none;
      font-size: 14px;
      font-weight: 500;
      color: #fff;
      background-color: #3498db;
      padding: 8px 16px;
      border-radius: 4px;
      transition: background-color 0.3s ease;
    }
    .paper-actions a:hover {
      background-color: #2980b9;
    }
    .heart-btn {
      cursor: pointer;
      font-size: 24px;
      filter: grayscale(1) brightness(0.8);
      transition: filter 0.3s ease, transform 0.2s ease;
    }
    .heart-btn:hover {
      filter: grayscale(0.8) brightness(1);
      transform: scale(1.1);
    }
    .heart-btn.active {
      filter: grayscale(0) drop-shadow(0 0 4px rgba(231, 76, 60, 0.5));
    }
    .star-wrapper {
      font-size: 1.3em;
      line-height: 1;
      display: inline-flex;
      align-items: center;
    }
    .half-star {
      display: inline-block;
      width: 0.5em;
      overflow: hidden;
      white-space: nowrap;
      vertical-align: middle;
    }
    .full-star {
      vertical-align: middle;
    }
    .footer {
      text-align: center;
      font-size: 12px;
      color: #888;
      margin-top: 24px;
      padding-top: 16px;
      border-top: 1px solid #ddd;
    }
    .footer a {
      color: #3498db;
      text-decoration: none;
    }
    .footer a:hover {
      text-decoration: underline;
    }
    .back-to-top {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background-color: #3498db;
      color: #fff;
      padding: 10px 16px;
      border-radius: 50%;
      text-decoration: none;
      font-size: 18px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
      transition: background-color 0.3s ease;
    }
    .back-to-top:hover {
      background-color: #2980b9;
    }
    /* Toast 提示条样式 */
    .toast {
      position: fixed;
      bottom: 20px;
      left: 50%;
      transform: translateX(-50%);
      background-color: #333;
      color: #fff;
      padding: 12px 24px;
      border-radius: 4px;
      font-size: 14px;
      opacity: 0;
      visibility: hidden;
      transition: opacity 0.3s ease, visibility 0.3s ease;
      z-index: 1000;
    }
    .toast.visible {
      opacity: 1;
      visibility: visible;
    }
    /* 模态框样式 */
    .modal {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.5);
      justify-content: center;
      align-items: center;
      z-index: 1000;
    }
    .modal.visible {
      display: flex;
    }
    .modal-content {
      background-color: #fff;
      border-radius: 8px;
      width: 90%;
      max-width: 800px;
      height: 80%;
      overflow: hidden;
      position: relative;
    }
    .modal-iframe {
      width: 100%;
      height: 100%;
      border: none;
    }
    .modal-actions {
      position: absolute;
      top: 10px;
      right: 10px;
      display: flex;
      gap: 8px;
    }
    .modal-button {
      background-color: #3498db;
      color: #fff;
      border: none;
      border-radius: 50%;
      width: 30px;
      height: 30px;
      font-size: 16px;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: background-color 0.3s ease;
    }
    .modal-button:hover {
      background-color: #2980b9;
    }
    .modal-button.close {
      background-color: #e74c3c;
    }
    .modal-button.close:hover {
      background-color: #c0392b;
    }
    /* 提示条样式 */
    .browser-prompt {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      background-color: #3498db;
      color: #fff;
      padding: 12px;
      text-align: center;
      z-index: 1000;
      display: none;
      display: block;
    }
    .browser-prompt a {
      color: #fff;
      text-decoration: underline;
      margin-left: 8px;
    }
    .browser-prompt a:hover {
      color: #f1c40f;
    }
  </style>
</head>
<body>

<!-- 提示条 -->
<div class="browser-prompt" id="browser-prompt">
  For the best experience, please open this page in your browser.
  <a href="https://xiangsam.github.io/arxiv-daily/">Open in Browser</a>
</div>

<div class="container">
  <div class="header">
    <h1>Daily Research Papers</h1>
    <p>Your daily dose of the latest research papers, curated just for you.</p>
  </div>

  <div>
    <br>
    <div class="paper-block">
        <div class="paper-title">Probabilistic Reasoning with LLMs for k-anonymity Estimation</div>
        <div class="paper-authors">Jonathan Zheng, Sauvik Das, Alan Ritter, Wei Xu</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Probabilistic Reasoning</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Probabilistic reasoning is a key aspect of both human and artificial
intelligence that allows for handling uncertainty and ambiguity in
decision-making. In this paper, we introduce a novel numerical reasoning task
under uncertainty, focusing on estimating the k-anonymity of user-generated
documents containing privacy-sensitive information. We propose BRANCH, which
uses LLMs to factorize a joint probability distribution to estimate the
k-value-the size of the population matching the given information-by modeling
individual pieces of textual information as random variables. The probability
of each factor occurring within a population is estimated using standalone LLMs
or retrieval-augmented generation systems, and these probabilities are combined
into a final k-value. Our experiments show that this method successfully
estimates the correct k-value 67% of the time, an 11% increase compared to
GPT-4o chain-of-thought reasoning. Additionally, we leverage LLM uncertainty to
develop prediction intervals for k-anonymity, which include the correct value
in nearly 92% of cases.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces BRANCH, a probabilistic reasoning framework using LLMs to estimate k-anonymity of privacy-sensitive documents, achieving a 67% accuracy rate and 92% prediction interval coverage.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09674v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBProbabilistic+Reasoning+with+LLMs+for+k-anonymity+Estimation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09674v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Have LLMs Made Active Learning Obsolete? Surveying the NLP Community</div>
        <div class="paper-authors">Julia Romberg, Christopher Schröder, Julius Gonsior, Katrin Tomanek, Fredrik Olsson</div>
        <div class="paper-affiliations">TUD Dresden University of Technology, GESIS -- Leibniz Institute for the Social Sciences, Independent Researcher, All Ears, Institute for Applied Informatics at Leipzig University (InfAI)</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Integration with Active Learning</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Supervised learning relies on annotated data, which is expensive to obtain. A
longstanding strategy to reduce annotation costs is active learning, an
iterative process, in which a human annotates only data instances deemed
informative by a model. Large language models (LLMs) have pushed the
effectiveness of active learning, but have also improved methods such as few-
or zero-shot learning, and text synthesis - thereby introducing potential
alternatives. This raises the question: has active learning become obsolete? To
answer this fully, we must look beyond literature to practical experiences. We
conduct an online survey in the NLP community to collect previously intangible
insights on the perceived relevance of data annotation, particularly focusing
on active learning, including best practices, obstacles and expected future
developments. Our findings show that annotated data remains a key factor, and
active learning continues to be relevant. While the majority of active learning
users find it effective, a comparison with a community survey from over a
decade ago reveals persistent challenges: setup complexity, estimation of cost
reduction, and tooling. We publish an anonymized version of the collected
dataset</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Active learning remains relevant in NLP despite advancements in LLMs, as annotated data continues to be a bottleneck, though challenges like setup complexity and cost estimation persist.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09701v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBHave+LLMs+Made+Active+Learning+Obsolete?+Surveying+the+NLP+Community%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09701v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Local Look-Ahead Guidance via Verifier-in-the-Loop for Automated Theorem Proving</div>
        <div class="paper-authors">Sara Rajaee, Kumar Pratik, Gabriele Cesa, Arash Behboodi</div>
        <div class="paper-affiliations">Qualcomm AI Research, University of Amsterdam</div>
        <div class="paper-tag"><strong>Tag:</strong> Reinforcement Learning for Theorem Proving</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The most promising recent methods for AI reasoning require applying variants
of reinforcement learning (RL) either on rolled out trajectories from the
model, even for the step-wise rewards, or large quantities of human annotated
trajectory data. The reliance on the rolled-out trajectory renders the compute
cost and time prohibitively high. In particular, the correctness of a reasoning
trajectory can typically only be judged at its completion, leading to sparse
rewards in RL or requiring expensive synthetic data generation in expert
iteration-like methods. In this work, we focus on the Automatic Theorem Proving
(ATP) task and propose a novel verifier-in-the-loop design, which unlike
existing approaches that leverage feedback on the entire reasoning trajectory,
employs an automated verifier to give intermediate feedback at each step of the
reasoning process. Using Lean as the verifier, we empirically show that the
step-by-step local verification produces a global improvement in the model's
reasoning accuracy and efficiency.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces a verifier-in-the-loop framework for automated theorem proving, using Lean to provide intermediate feedback at each step, improving reasoning accuracy and efficiency.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09730v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLocal+Look-Ahead+Guidance+via+Verifier-in-the-Loop+for+Automated+Theorem+Proving%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09730v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Review GIDE -- Restaurant Review Gastrointestinal Illness Detection and Extraction with Large Language Models</div>
        <div class="paper-authors">Timothy Laurence, Joshua Harris, Leo Loman, Amy Douglas, Yung-Wai Chan, ...</div>
        <div class="paper-affiliations">UK Health Security Agency</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM for Public Health Surveillance</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Foodborne gastrointestinal (GI) illness is a common cause of ill health in
the UK. However, many cases do not interact with the healthcare system, posing
significant challenges for traditional surveillance methods. The growth of
publicly available online restaurant reviews and advancements in large language
models (LLMs) present potential opportunities to extend disease surveillance by
identifying public reports of GI illness. In this study, we introduce a novel
annotation schema, developed with experts in GI illness, applied to the Yelp
Open Dataset of reviews. Our annotations extend beyond binary disease
detection, to include detailed extraction of information on symptoms and foods.
We evaluate the performance of open-weight LLMs across these three tasks: GI
illness detection, symptom extraction, and food extraction. We compare this
performance to RoBERTa-based classification models fine-tuned specifically for
these tasks. Our results show that using prompt-based approaches, LLMs achieve
micro-F1 scores of over 90% for all three of our tasks. Using prompting alone,
we achieve micro-F1 scores that exceed those of smaller fine-tuned models. We
further demonstrate the robustness of LLMs in GI illness detection across three
bias-focused experiments. Our results suggest that publicly available review
text and LLMs offer substantial potential for public health surveillance of GI
illness by enabling highly effective extraction of key information. While LLMs
appear to exhibit minimal bias in processing, the inherent limitations of
restaurant review data highlight the need for cautious interpretation of
results.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Large Language Models (LLMs) achieve high accuracy in detecting gastrointestinal illness, extracting symptoms, and identifying foods from restaurant reviews, offering significant potential for public health surveillance.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09743v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBReview+GIDE+--+Restaurant+Review+Gastrointestinal+Illness+Detection+and+Extraction+with+Large+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09743v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Efficient Multi-Task Inferencing: Model Merging with Gromov-Wasserstein Feature Alignment</div>
        <div class="paper-authors">Luyang Fang, Ehsan Latif, Haoran Lu, Yifan Zhou, Ping Ma, ...</div>
        <div class="paper-affiliations">AI4STEM Education Center, Athens, GA, USA, School of Computing, University of Georgia, Athens, GA, USA, Department of Mathematics, Science, and Social Studies Education, University of Georgia, Athens, GA, USA, Department of Statistics, University of Georgia, Athens, GA, USA</div>
        <div class="paper-tag"><strong>Tag:</strong> Model Merging Techniques in NLP</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Automatic scoring of student responses enhances efficiency in education, but
deploying a separate neural network for each task increases storage demands,
maintenance efforts, and redundant computations. To address these challenges,
this paper introduces the Gromov-Wasserstein Scoring Model Merging (GW-SMM)
method, which merges models based on feature distribution similarities measured
via the Gromov-Wasserstein distance. Our approach begins by extracting features
from student responses using individual models, capturing both item-specific
context and unique learned representations. The Gromov-Wasserstein distance
then quantifies the similarity between these feature distributions, identifying
the most compatible models for merging. Models exhibiting the smallest pairwise
distances, typically in pairs or trios, are merged by combining only the shared
layers preceding the classification head. This strategy results in a unified
feature extractor while preserving separate classification heads for
item-specific scoring. We validated our approach against human expert knowledge
and a GPT-o1-based merging method. GW-SMM consistently outperformed both,
achieving a higher micro F1 score, macro F1 score, exact match accuracy, and
per-label accuracy. The improvements in micro F1 and per-label accuracy were
statistically significant compared to GPT-o1-based merging (p=0.04, p=0.01).
Additionally, GW-SMM reduced storage requirements by half without compromising
much accuracy, demonstrating its computational efficiency alongside reliable
scoring performance.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Gromov-Wasserstein Scoring Model Merging (GW-SMM), a method that merges models based on feature distribution similarities using the Gromov-Wasserstein distance, achieving efficient multi-task inferencing with reduced storage and computational demands while maintaining high accuracy.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09774v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBEfficient+Multi-Task+Inferencing:+Model+Merging+with+Gromov-Wasserstein+Feature+Alignment%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09774v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents</div>
        <div class="paper-authors">Arman Zharmagambetov, Chuan Guo, Ivan Evtimov, Maya Pavlova, Ruslan Salakhutdinov, ...</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Privacy Leakage Mitigation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> LLM-powered AI agents are an emerging frontier with tremendous potential to
increase human productivity. However, empowering AI agents to take action on
their user's behalf in day-to-day tasks involves giving them access to
potentially sensitive and private information, which leads to a possible risk
of inadvertent privacy leakage when the agent malfunctions. In this work, we
propose one way to address that potential risk, by training AI agents to better
satisfy the privacy principle of data minimization. For the purposes of this
benchmark, by "data minimization" we mean instances where private information
is shared only when it is necessary to fulfill a specific task-relevant
purpose. We develop a benchmark called AgentDAM to evaluate how well existing
and future AI agents can limit processing of potentially private information
that we designate "necessary" to fulfill the task. Our benchmark simulates
realistic web interaction scenarios and is adaptable to all existing web
navigation agents. We use AgentDAM to evaluate how well AI agents built on top
of GPT-4, Llama-3 and Claude can limit processing of potentially private
information when unnecessary, and show that these agents are often prone to
inadvertent use of unnecessary sensitive information. We finally propose a
prompting-based approach that reduces this.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> AgentDAM is a benchmark designed to evaluate and mitigate privacy leakage in LLM-powered AI agents by enforcing data minimization principles during web interactions.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09780v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAgentDAM:+Privacy+Leakage+Evaluation+for+Autonomous+Web+Agents%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09780v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Constrained Language Generation with Discrete Diffusion Models</div>
        <div class="paper-authors">Michael Cardei, Jacob K Christopher, Thomas Hartvigsen, Brian R. Bartoldson, Bhavya Kailkhura, ...</div>
        <div class="paper-affiliations">University of Virginia, Lawrence Livermore National Laboratory</div>
        <div class="paper-tag"><strong>Tag:</strong> Differentiable Optimization in Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Constraints are critical in text generation as LLM outputs are often
unreliable when it comes to ensuring generated outputs adhere to user defined
instruction or general safety guidelines. To address this gap, we present
Constrained Discrete Diffusion (CDD), a novel method for enforcing constraints
on natural language by integrating discrete diffusion models with
differentiable optimization. Unlike conventional text generators, which often
rely on post-hoc filtering or model retraining for controllable generation, we
propose imposing constraints directly into the discrete diffusion sampling
process. We illustrate how this technique can be applied to satisfy a variety
of natural language constraints, including (i) toxicity mitigation by
preventing harmful content from emerging, (ii) character and sequence level
lexical constraints, and (iii) novel molecule sequence generation with specific
property adherence. Experimental results show that our constraint-aware
procedure achieves high fidelity in meeting these requirements while preserving
fluency and semantic coherence, outperforming auto-regressive and existing
discrete diffusion approaches.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Constrained Discrete Diffusion (CDD) integrates discrete diffusion models with differentiable optimization to enforce constraints during language generation, achieving state-of-the-art results in toxicity mitigation, lexical constraints, and molecular sequence generation.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09790v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBConstrained+Language+Generation+with+Discrete+Diffusion+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09790v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Attention Reveals More Than Tokens: Training-Free Long-Context Reasoning with Attention-guided Retrieval</div>
        <div class="paper-authors">Yuwei Zhang, Jayanth Srinivasa, Gaowen Liu, Jingbo Shang</div>
        <div class="paper-affiliations">University of California, San Diego, Cisco</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Attention Mechanisms</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Models (LLMs) often exhibit substantially shorter effective
context lengths than their claimed capacities, especially when handling complex
reasoning tasks that require integrating information from multiple parts of a
long context and performing multi-step reasoning. Although Chain-of-Thought
(CoT) prompting has shown promise in reducing task complexity, our empirical
analysis reveals that it does not fully resolve this limitation. Through
controlled experiments, we identify poor recall of implicit facts as the
primary cause of failure, which significantly hampers reasoning performance.
Interestingly, we observe that the internal attention weights from the
generated CoT tokens can effectively ground implicit facts, even when these
facts are not explicitly recalled. Building on this insight, we propose a novel
training-free algorithm, Attrieval, which leverages attention weights to
retrieve relevant facts from the long context and incorporates them into the
reasoning process. Additionally, we find that selecting context tokens from CoT
tokens further improves performance. Our results demonstrate that Attrieval
enhances long-context reasoning capability notably on both synthetic and
real-world QA datasets with various models.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Attrieval, a training-free algorithm that leverages attention weights from Chain-of-Thought tokens to retrieve implicit facts and enhance long-context reasoning in Large Language Models.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09819v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAttention+Reveals+More+Than+Tokens:+Training-Free+Long-Context+Reasoning+with+Attention-guided+Retrieval%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09819v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Generative AI for Named Entity Recognition in Low-Resource Language Nepali</div>
        <div class="paper-authors">Sameer Neupane, Jeevan Chapagain, Nobal B. Niraula, Diwa Koirala</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Low-Resource Language NER with LLMs</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Generative Artificial Intelligence (GenAI), particularly Large Language
Models (LLMs), has significantly advanced Natural Language Processing (NLP)
tasks, such as Named Entity Recognition (NER), which involves identifying
entities like person, location, and organization names in text. LLMs are
especially promising for low-resource languages due to their ability to learn
from limited data. However, the performance of GenAI models for Nepali, a
low-resource language, has not been thoroughly evaluated. This paper
investigates the application of state-of-the-art LLMs for Nepali NER,
conducting experiments with various prompting techniques to assess their
effectiveness. Our results provide insights into the challenges and
opportunities of using LLMs for NER in low-resource settings and offer valuable
contributions to the advancement of NLP research in languages like Nepali.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper evaluates the effectiveness of state-of-the-art Large Language Models for Named Entity Recognition in the low-resource language Nepali, highlighting challenges and opportunities.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09822v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBGenerative+AI+for+Named+Entity+Recognition+in+Low-Resource+Language+Nepali%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09822v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Who Are You Behind the Screen? Implicit MBTI and Gender Detection Using Artificial Intelligence</div>
        <div class="paper-authors">Kourosh Shahnazari, Seyed Moein Ayyoubzadeh</div>
        <div class="paper-affiliations">Sharif University of Technology</div>
        <div class="paper-tag"><strong>Tag:</strong> Transformer-based Personality Classification</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> In personalized technology and psychological research, precisely detecting
demographic features and personality traits from digital interactions becomes
ever more important. This work investigates implicit categorization, inferring
personality and gender variables directly from linguistic patterns in Telegram
conversation data, while conventional personality prediction techniques mostly
depend on explicitly self-reported labels. We refine a Transformer-based
language model (RoBERTa) to capture complex linguistic cues indicative of
personality traits and gender differences using a dataset comprising 138,866
messages from 1,602 users annotated with MBTI types and 195,016 messages from
2,598 users annotated with gender. Confidence levels help to greatly raise
model accuracy to 86.16\%, hence proving RoBERTa's capacity to consistently
identify implicit personality types from conversational text data. Our results
highlight the usefulness of Transformer topologies for implicit personality and
gender classification, hence stressing their efficiency and stressing important
trade-offs between accuracy and coverage in realistic conversational
environments. With regard to gender classification, the model obtained an
accuracy of 74.4\%, therefore capturing gender-specific language patterns.
Personality dimension analysis showed that people with introverted and
intuitive preferences are especially more active in text-based interactions.
This study emphasizes practical issues in balancing accuracy and data coverage
as Transformer-based models show their efficiency in implicit personality and
gender prediction tasks from conversational texts.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This study demonstrates the effectiveness of RoBERTa, a Transformer-based language model, in accurately classifying MBTI personality types and gender from Telegram conversational data, highlighting its potential for implicit psychological and demographic profiling.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09853v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBWho+Are+You+Behind+the+Screen?+Implicit+MBTI+and+Gender+Detection+Using+Artificial+Intelligence%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09853v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Media and responsible AI governance: a game-theoretic and LLM analysis</div>
        <div class="paper-authors">Nataliya Balabanova, Adeela Bashir, Paolo Bova, Alessio Buscemi, Theodor Cimpeanu, ...</div>
        <div class="paper-affiliations">Peking University, TsingHua University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM in Regulatory Dynamics</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> This paper investigates the complex interplay between AI developers,
regulators, users, and the media in fostering trustworthy AI systems. Using
evolutionary game theory and large language models (LLMs), we model the
strategic interactions among these actors under different regulatory regimes.
The research explores two key mechanisms for achieving responsible governance,
safe AI development and adoption of safe AI: incentivising effective regulation
through media reporting, and conditioning user trust on commentariats'
recommendation. The findings highlight the crucial role of the media in
providing information to users, potentially acting as a form of "soft"
regulation by investigating developers or regulators, as a substitute to
institutional AI regulation (which is still absent in many regions). Both
game-theoretic analysis and LLM-based simulations reveal conditions under which
effective regulation and trustworthy AI development emerge, emphasising the
importance of considering the influence of different regulatory regimes from an
evolutionary game-theoretic perspective. The study concludes that effective
governance requires managing incentives and costs for high quality
commentaries.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper explores the role of media in AI governance using evolutionary game theory and LLMs, highlighting how media can act as 'soft' regulation to foster trustworthy AI development and user trust.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09858v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBMedia+and+responsible+AI+governance:+a+game-theoretic+and+LLM+analysis%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09858v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">What's In Your Field? Mapping Scientific Research with Knowledge Graphs and Large Language Models</div>
        <div class="paper-authors">Abhipsha Das, Nicholas Lourie, Siavash Golkar, Mariel Pettee</div>
        <div class="paper-affiliations">Polymathic AI, Lawrence Berkeley National Laboratory, New York University, Flatiron Institute</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM-based Knowledge Graph Construction</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The scientific literature's exponential growth makes it increasingly
challenging to navigate and synthesize knowledge across disciplines. Large
language models (LLMs) are powerful tools for understanding scientific text,
but they fail to capture detailed relationships across large bodies of work.
Unstructured approaches, like retrieval augmented generation, can sift through
such corpora to recall relevant facts; however, when millions of facts
influence the answer, unstructured approaches become cost prohibitive.
Structured representations offer a natural complement -- enabling systematic
analysis across the whole corpus. Recent work enhances LLMs with unstructured
or semistructured representations of scientific concepts; to complement this,
we try extracting structured representations using LLMs. By combining LLMs'
semantic understanding with a schema of scientific concepts, we prototype a
system that answers precise questions about the literature as a whole. Our
schema applies across scientific fields and we extract concepts from it using
only 20 manually annotated abstracts. To demonstrate the system, we extract
concepts from 30,000 papers on arXiv spanning astrophysics, fluid dynamics, and
evolutionary biology. The resulting database highlights emerging trends and, by
visualizing the knowledge graph, offers new ways to explore the ever-growing
landscape of scientific knowledge. Demo: abby101/surveyor-0 on HF Spaces. Code:
https://github.com/chiral-carbon/kg-for-science.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces a system combining large language models (LLMs) with structured knowledge representation to extract and analyze scientific concepts from literature, enabling systematic exploration of research trends and cross-disciplinary connections.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09894v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBWhat%27s+In+Your+Field?+Mapping+Scientific+Research+with+Knowledge+Graphs+and+Large+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09894v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">A Rule Based Solution to Co-reference Resolution in Clinical Text</div>
        <div class="paper-authors">Ping Chen, David Hinote, Guoqing Chen</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Clinical Text Co-reference Resolution</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Objective: The aim of this study was to build an effective co-reference
resolution system tailored for the biomedical domain. Materials and Methods:
Experiment materials used in this study is provided by the 2011 i2b2 Natural
Language Processing Challenge. The 2011 i2b2 challenge involves coreference
resolution in medical documents. Concept mentions have been annotated in
clinical texts, and the mentions that co-refer in each document are to be
linked by coreference chains. Normally, there are two ways of constructing a
system to automatically discover co-referent links. One is to manually build
rules for co-reference resolution, and the other category of approaches is to
use machine learning systems to learn automatically from training datasets and
then perform the resolution task on testing datasets. Results: Experiments show
the existing co-reference resolution systems are able to find some of the
co-referent links, and our rule based system performs well finding the majority
of the co-referent links. Our system achieved 89.6% overall performance on
multiple medical datasets. Conclusion: The experiment results show that
manually crafted rules based on observation of training data is a valid way to
accomplish high performance in this coreference resolution task for the
critical biomedical domain.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> A rule-based system for co-reference resolution in clinical texts achieves 89.6% performance, demonstrating the effectiveness of manually crafted rules in the biomedical domain.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09896v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBA+Rule+Based+Solution+to+Co-reference+Resolution+in+Clinical+Text%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09896v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Developing and Evaluating an AI-Assisted Prediction Model for Unplanned Intensive Care Admissions following Elective Neurosurgery using Natural Language Processing within an Electronic Healthcare Record System</div>
        <div class="paper-authors">Julia Ive, Olatomiwa Olukoya, Jonathan P. Funnell, James Booker, Sze H M Lam, ...</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> NLP in Electronic Health Records</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Introduction: Timely care in a specialised neuro-intensive therapy unit (ITU)
reduces mortality and hospital stays, with planned admissions being safer than
unplanned ones. However, post-operative care decisions remain subjective. This
study used artificial intelligence (AI), specifically natural language
processing (NLP) to analyse electronic health records (EHRs) and predict ITU
admissions for elective surgery patients. Methods: This study analysed the EHRs
of elective neurosurgery patients from University College London Hospital
(UCLH) using NLP. Patients were categorised into planned high dependency unit
(HDU) or ITU admission; unplanned HDU or ITU admission; or ward / overnight
recovery (ONR). The Medical Concept Annotation Tool (MedCAT) was used to
identify SNOMED-CT concepts within the clinical notes. We then explored the
utility of these identified concepts for a range of AI algorithms trained to
predict ITU admission. Results: The CogStack-MedCAT NLP model, initially
trained on hospital-wide EHRs, underwent two refinements: first with data from
patients with Normal Pressure Hydrocephalus (NPH) and then with data from
Vestibular Schwannoma (VS) patients, achieving a concept detection F1-score of
0.93. This refined model was then used to extract concepts from EHR notes of
2,268 eligible neurosurgical patients. We integrated the extracted concepts
into AI models, including a decision tree model and a neural time-series model.
Using the simpler decision tree model, we achieved a recall of 0.87 (CI 0.82 -
0.91) for ITU admissions, reducing the proportion of unplanned ITU cases missed
by human experts from 36% to 4%. Conclusion: The NLP model, refined for
accuracy, has proven its efficiency in extracting relevant concepts, providing
a reliable basis for predictive AI models to use in clinically valid
applications.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> An AI-assisted prediction model using NLP was developed to predict unplanned intensive care admissions following elective neurosurgery, achieving high accuracy and reducing missed cases by human experts.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09927v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDeveloping+and+Evaluating+an+AI-Assisted+Prediction+Model+for+Unplanned+Intensive+Care+Admissions+following+Elective+Neurosurgery+using+Natural+Language+Processing+within+an+Electronic+Healthcare+Record+System%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09927v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Take Off the Training Wheels Progressive In-Context Learning for Effective Alignment</div>
        <div class="paper-authors">Zhenyu Liu, Dongfang Li, Xinshuo Hu, Xinping Zhao, Yibin Chen, ...</div>
        <div class="paper-affiliations">Huawei Cloud, Huawei Technologies Ltd., Harbin Institute of Technology (Shenzhen)</div>
        <div class="paper-tag"><strong>Tag:</strong> In-Context Learning for Complex Generation Tasks</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Recent studies have explored the working mechanisms of In-Context Learning
(ICL). However, they mainly focus on classification and simple generation
tasks, limiting their broader application to more complex generation tasks in
practice. To address this gap, we investigate the impact of demonstrations on
token representations within the practical alignment tasks. We find that the
transformer embeds the task function learned from demonstrations into the
separator token representation, which plays an important role in the generation
of prior response tokens. Once the prior response tokens are determined, the
demonstrations become redundant.Motivated by this finding, we propose an
efficient Progressive In-Context Alignment (PICA) method consisting of two
stages. In the first few-shot stage, the model generates several prior response
tokens via standard ICL while concurrently extracting the ICL vector that
stores the task function from the separator token representation. In the
following zero-shot stage, this ICL vector guides the model to generate
responses without further demonstrations.Extensive experiments demonstrate that
our PICA not only surpasses vanilla ICL but also achieves comparable
performance to other alignment tuning methods. The proposed training-free
method reduces the time cost (e.g., 5.45+) with improved alignment performance
(e.g., 6.57+). Consequently, our work highlights the application of ICL for
alignment and calls for a deeper understanding of ICL for complex generations.
The code will be available at https://github.com/HITsz-TMG/PICA.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Progressive In-Context Alignment (PICA), a two-stage method that reduces the need for demonstrations in in-context learning by extracting task functions from separator tokens, achieving comparable performance to SFT and RLHF.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.09958v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBTake+Off+the+Training+Wheels+Progressive+In-Context+Learning+for+Effective+Alignment%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.09958v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">A New Benchmark for Few-Shot Class-Incremental Learning: Redefining the Upper Bound</div>
        <div class="paper-authors">Shiwon Kim, Dongjun Hwang, Sungwon Woo, Rita Singh</div>
        <div class="paper-affiliations">Sogang University, Yonsei University, Carnegie Mellon University</div>
        <div class="paper-tag"><strong>Tag:</strong> Imbalanced Learning in Few-Shot Class-Incremental Learning</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Class-incremental learning (CIL) aims to continuously adapt to emerging
classes while retaining knowledge of previously learned ones. Few-shot
class-incremental learning (FSCIL) presents an even greater challenge which
requires the model to learn incremental classes with only a limited number of
samples. In conventional CIL, joint training is widely considered the upper
bound, serving as both a benchmark and a methodological guide. However, we find
that joint training fails to be a meaningful upper bound in FSCIL due to the
inherent difficulty of inter-task class separation (ICS) caused by severe class
imbalance. In this work, we introduce a new joint training benchmark tailored
for FSCIL by integrating imbalance-aware techniques, effectively bridging the
performance gap between base and incremental classes. Furthermore, we point out
inconsistencies in the experimental setup and evaluation of existing FSCIL
methods. To ensure fair comparisons between different FSCIL approaches and
joint training, we standardize training conditions and propose a unified
evaluation protocol that simultaneously considers the validation set and
computational complexity. By establishing a reliable upper bound and a
standardized evaluation framework for FSCIL, our work provides a clear
benchmark and a practical foundation for future research.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces a new joint training benchmark for few-shot class-incremental learning (FSCIL) by integrating imbalance-aware techniques and proposes a standardized evaluation protocol to ensure fair comparisons across methods.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10003v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBA+New+Benchmark+for+Few-Shot+Class-Incremental+Learning:+Redefining+the+Upper+Bound%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10003v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model</div>
        <div class="paper-authors">Bowen Zhang, Pengcheng Luo</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM for Mathematical Optimization</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Operations Research (OR) has been widely applied in various fields such as
resource allocation, production planning, and supply chain management. However,
addressing real-world OR problems requires OR experts to perform mathematical
modeling and programmers to develop solution algorithms. This traditional
method, heavily reliant on experts, is costly and has long development cycles,
severely limiting the widespread adoption of OR techniques. Few have considered
using Artificial Intelligence (AI) to replace professionals to achieve fully
automated solutions for OR problems. We propose OR-LLM-Agent, the first AI
agent that enables end-to-end automation for solving real-world OR problems.
OR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of
Large Language Models (LLMs) to translate natural language problem descriptions
into formal mathematical models and automatically generate Gurobi solver code.
In OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair
within a sandbox environment, facilitating the derivation of the final
solution. Due to the lack of dedicated benchmark datasets for evaluating the
automated solving of OR problems, we construct a benchmark dataset comprising
83 real-world OR problems described in natural language. We conduct comparative
experiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini,
DeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the
highest pass rate of 100% and the highest solution accuracy of 85%,
demonstrating the feasibility of automated OR problem-solving. Data and code
have been publicly available at https://github.com/bwz96sco/or_llm_agent.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> OR-LLM-Agent is the first AI agent framework that automates the entire Operations Research workflow, from natural language problem descriptions to mathematical modeling, code generation, and optimal solutions, leveraging reasoning Large Language Models.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10009v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBOR-LLM-Agent:+Automating+Modeling+and+Solving+of+Operations+Research+Optimization+Problem+with+Reasoning+Large+Language+Model%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10009v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Using Context to Improve Word Segmentation</div>
        <div class="paper-authors">Stephanie Hu, Xiaolu Guo</div>
        <div class="paper-affiliations"></div>
        <div class="paper-tag"><strong>Tag:</strong> Statistical Word Segmentation Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> An important step in understanding how children acquire languages is studying
how infants learn word segmentation. It has been established in previous
research that infants may use statistical regularities in speech to learn word
segmentation. The research of Goldwater et al., demonstrated that incorporating
context in models improves their ability to learn word segmentation. We
implemented two of their models, a unigram and bigram model, to examine how
context can improve statistical word segmentation. The results are consistent
with our hypothesis that the bigram model outperforms the unigram model at
predicting word segmentation. Extending the work of Goldwater et al., we also
explored basic ways to model how young children might use previously learned
words to segment new utterances.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Incorporating context, particularly through a bigram model, significantly improves word segmentation performance compared to a unigram model, suggesting that context aids in learning word boundaries.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10023v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBUsing+Context+to+Improve+Word+Segmentation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10023v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM</div>
        <div class="paper-authors">Mohd Ariful Haque, Justin Williams, Sunzida Siddique, Md. Hujaifa Islam, Hasmot Ali, ...</div>
        <div class="paper-affiliations">Ahsanullah University of Science and Technology, Clark Atlanta University, Daffodil International University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Tool Generation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The combination of LLM agents with external tools enables models to solve
complex tasks beyond their knowledge base. Human-designed tools are inflexible
and restricted to solutions within the scope of pre-existing tools created by
experts. To address this problem, we propose ATLASS, an advanced tool learning
and selection system designed as a closed-loop framework. It enables the LLM to
solve problems by dynamically generating external tools on demand. In this
framework, agents play a crucial role in orchestrating tool selection,
execution, and refinement, ensuring adaptive problem-solving capabilities. The
operation of ATLASS follows three phases: The first phase, Understanding Tool
Requirements, involves the Agents determining whether tools are required and
specifying their functionality; the second phase, Tool Retrieval/Generation,
involves the Agents retrieving or generating tools based on their availability;
and the third phase, Task Solving, involves combining all the component tools
necessary to complete the initial task. The Tool Dataset stores the generated
tools, ensuring reusability and minimizing inference cost. Current LLM-based
tool generation systems have difficulty creating complex tools that need APIs
or external packages. In ATLASS, we solve the problem by automatically setting
up the environment, fetching relevant API documentation online, and using a
Python interpreter to create a reliable, versatile tool that works in a wider
range of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and
ethical concerns are handled through human feedback before executing generated
code. By addressing the limitations of predefined toolsets and enhancing
adaptability, ATLASS serves as a real-world solution that empowers users with
dynamically generated tools for complex problem-solving.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> ATLASS is a closed-loop framework that enables LLMs to dynamically generate and select tools for solving complex tasks, enhancing adaptability and reusability.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10071v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAdvanced+Tool+Learning+and+Selection+System+%28ATLASS%29:+A+Closed-Loop+Framework+Using+LLM%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10071v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Parallelizing Multi-objective A* Search</div>
        <div class="paper-authors">Saman Ahmadi, Nathan R. Sturtevant, Andrea Raith, Daniel Harabor, Mahdi Jalili</div>
        <div class="paper-affiliations">RMIT University, University of Auckland, Monash University, University of Alberta</div>
        <div class="paper-tag"><strong>Tag:</strong> Parallel Heuristic Search Algorithms</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The Multi-objective Shortest Path (MOSP) problem is a classic network
optimization problem that aims to find all Pareto-optimal paths between two
points in a graph with multiple edge costs. Recent studies on multi-objective
search with A* (MOA*) have demonstrated superior performance in solving
difficult MOSP instances. This paper presents a novel search framework that
allows efficient parallelization of MOA* with different objective orders. The
framework incorporates a unique upper bounding strategy that helps the search
reduce the problem's dimensionality to one in certain cases. Experimental
results demonstrate that the proposed framework can enhance the performance of
recent A*-based solutions, with the speed-up proportional to the problem
dimension.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper introduces a novel parallel framework for Multi-objective A* (MOA*) search, enhancing performance by utilizing different objective orderings and an innovative upper bounding technique, achieving significant speed-ups in solving Multi-objective Shortest Path (MOSP) problems.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10075v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBParallelizing+Multi-objective+A%2A+Search%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10075v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Information Density Principle for MLLM Benchmarks</div>
        <div class="paper-authors">Chunyi Li, Xiaozhe Li, Zicheng Zhang, Yuan Tian, Ziheng Jia, ...</div>
        <div class="paper-affiliations">Shanghai Jiao Tong University, Tongji University, Shanghai AI Lab</div>
        <div class="paper-tag"><strong>Tag:</strong> MLLM Benchmark Evaluation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> With the emergence of Multimodal Large Language Models (MLLMs), hundreds of
benchmarks have been developed to ensure the reliability of MLLMs in downstream
tasks. However, the evaluation mechanism itself may not be reliable. For
developers of MLLMs, questions remain about which benchmark to use and whether
the test results meet their requirements. Therefore, we propose a critical
principle of Information Density, which examines how much insight a benchmark
can provide for the development of MLLMs. We characterize it from four key
dimensions: (1) Fallacy, (2) Difficulty, (3) Redundancy, (4) Diversity. Through
a comprehensive analysis of more than 10,000 samples, we measured the
information density of 19 MLLM benchmarks. Experiments show that using the
latest benchmarks in testing can provide more insight compared to previous
ones, but there is still room for improvement in their information density. We
hope this principle can promote the development and application of future MLLM
benchmarks. Project page: https://github.com/lcysyzxdxc/bench4bench</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces the Information Density principle to evaluate multimodal benchmarks for MLLMs, focusing on Fallacy, Difficulty, Redundancy, and Diversity, and provides a Human-Model-Data pipeline for benchmark developers.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10079v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBInformation+Density+Principle+for+MLLM+Benchmarks%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10079v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Why Does Your CoT Prompt (Not) Work? Theoretical Analysis of Prompt Space Complexity, its Interaction with Answer Space During CoT Reasoning with LLMs: A Recurrent Perspective</div>
        <div class="paper-authors">Xiang Zhang, Juntai Cao, Jiaqi Wei, Chenyu You, Dujian Ding</div>
        <div class="paper-affiliations">University of British Columbia, Zhejiang University, Stony Brook University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Prompt Optimization</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Despite the remarkable successes of Large Language Models (LLMs), their
fundamental Transformer architecture possesses inherent theoretical limitations
that restrict their capability to handle reasoning tasks with increasing
computational complexity. Chain-of-Thought (CoT) prompting has emerged as a
practical solution, supported by several theoretical studies. However, current
CoT-based methods (including ToT, GoT, etc.) generally adopt a
"one-prompt-fits-all" strategy, using fixed templates (e.g., "think step by
step") across diverse reasoning tasks. This method forces models to navigate an
extremely complex prompt space to identify effective reasoning paths. The
current prompt designing research are also heavily relying on trial-and-error
rather than theoretically informed guidance. In this paper, we provide a
rigorous theoretical analysis of the complexity and interplay between two
crucial spaces: the prompt space (the space of potential prompt structures) and
the answer space (the space of reasoning solutions generated by LLMs) in CoT
reasoning. We demonstrate how reliance on a single universal prompt (e.g. think
step by step) can negatively impact the theoretical computability of LLMs,
illustrating that prompt complexity directly influences the structure and
effectiveness of the navigation in answer space. Our analysis highlights that
sometimes human supervision is critical for efficiently navigating the prompt
space. We theoretically and empirically show that task-specific prompting
significantly outperforms unsupervised prompt generation, emphasizing the
necessity of thoughtful human guidance in CoT prompting.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper theoretically analyzes the complexity of prompt and answer spaces in Chain-of-Thought (CoT) reasoning with LLMs, showing that task-specific supervised prompting significantly outperforms unsupervised methods.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10084v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBWhy+Does+Your+CoT+Prompt+%28Not%29+Work?+Theoretical+Analysis+of+Prompt+Space+Complexity%2C+its+Interaction+with+Answer+Space+During+CoT+Reasoning+with+LLMs:+A+Recurrent+Perspective%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10084v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model</div>
        <div class="paper-authors">Qiyuan Deng, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, ...</div>
        <div class="paper-affiliations">Harbin Institute of Technology</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Safety Alignment</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Reinforcement Learning (RL) algorithms for safety alignment of Large Language
Models (LLMs), such as Direct Preference Optimization (DPO), encounter the
challenge of distribution shift. Current approaches typically address this
issue through online sampling from the target policy, which requires
significant computational resources. In this paper, we hypothesize that during
off-policy training, while the ranking order of output generated by policy
changes, their overall distribution remains relatively stable. This stability
allows the transformation of the sampling process from the target policy into a
re-ranking of preference data. Building on this hypothesis, We propose a new
framework that leverages the model's intrinsic safety judgment capability to
extract reward signals, which are then used to calculate label confidence for
preferences reordering. Extensive experimental results and theoretical analysis
demonstrate that the proposed method effectively addresses the distribution
shift issue, remarkably enhancing the safety performance while reducing about
300x computational overheads.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper proposes a computationally efficient framework for safety alignment in Large Language Models by re-ranking preference data using intrinsic reward signals, reducing computational overhead by 300x.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10093v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBRepresentation-based+Reward+Modeling+for+Efficient+Safety+Alignment+of+Large+Language+Model%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10093v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Semantic Synergy: Unlocking Policy Insights and Learning Pathways Through Advanced Skill Mapping</div>
        <div class="paper-authors">Phoebe Koundouri, Conrad Landis, Georgios Feretzakis</div>
        <div class="paper-affiliations">Athena Research Centre, Denmark Technical University, Athens University of Economics and Business, UN SDSN</div>
        <div class="paper-tag"><strong>Tag:</strong> Skill Extraction and Mapping in NLP</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> This research introduces a comprehensive system based on state-of-the-art
natural language processing, semantic embedding, and efficient search
techniques for retrieving similarities and thus generating actionable insights
from raw textual information. The system automatically extracts and aggregates
normalized competencies from multiple documents (such as policy files and
curricula vitae) and creates strong relationships between recognized
competencies, occupation profiles, and related learning courses. To validate
its performance, we conducted a multi-tier evaluation that included both
explicit and implicit skill references in synthetic and real-world documents.
The results showed near-human-level accuracy, with F1 scores exceeding 0.95 for
explicit skill detection and above 0.93 for implicit mentions. The system
thereby establishes a sound foundation for supporting in-depth collaboration
across the AE4RIA network. The methodology involves a multi-stage pipeline
based on extensive preprocessing and data cleaning, semantic embedding and
segmentation via SentenceTransformer, and skill extraction using a FAISS-based
search method. The extracted skills are associated with occupation frameworks
(as formulated in the ESCO ontology) and with learning paths offered through
the Sustainable Development Goals Academy. Moreover, interactive visualization
software, implemented with Dash and Plotly, presents graphs and tables for
real-time exploration and informed decision-making by those involved in
policymaking, training and learning supply, career transitions, and
recruitment. Overall, this system, backed by rigorous validation, offers
promising prospects for improved policymaking, human resource development, and
lifelong learning by providing structured and actionable insights from raw,
complex textual information.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> This paper presents a system leveraging NLP, semantic embeddings, and FAISS-based search to extract and map skills from unstructured text, enabling actionable insights for policymaking, workforce development, and education.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10094v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBSemantic+Synergy:+Unlocking+Policy+Insights+and+Learning+Pathways+Through+Advanced+Skill+Mapping%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10094v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Cognitive-Mental-LLM: Leveraging Reasoning in Large Language Models for Mental Health Prediction via Online Text</div>
        <div class="paper-authors">Avinash Patil, Amardeep Kour Gedhu</div>
        <div class="paper-affiliations">Santa Clara University, Arizona State University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Reasoning Techniques</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Models (LLMs) have demonstrated potential in predicting mental
health outcomes from online text, yet traditional classification methods often
lack interpretability and robustness. This study evaluates structured reasoning
techniques-Chain-of-Thought (CoT), Self-Consistency (SC-CoT), and
Tree-of-Thought (ToT)-to improve classification accuracy across multiple mental
health datasets sourced from Reddit. We analyze reasoning-driven prompting
strategies, including Zero-shot CoT and Few-shot CoT, using key performance
metrics such as Balanced Accuracy, F1 score, and Sensitivity/Specificity. Our
findings indicate that reasoning-enhanced techniques improve classification
performance over direct prediction, particularly in complex cases. Compared to
baselines such as Zero Shot non-CoT Prompting, and fine-tuned pre-trained
transformers such as BERT and Mental-RoBerta, and fine-tuned Open Source LLMs
such as Mental Alpaca and Mental-Flan-T5, reasoning-driven LLMs yield notable
gains on datasets like Dreaddit (+0.52\% over M-LLM, +0.82\% over BERT) and
SDCNL (+4.67\% over M-LLM, +2.17\% over BERT). However, performance declines in
Depression Severity, and CSSRS predictions suggest dataset-specific
limitations, likely due to our using a more extensive test set. Among prompting
strategies, Few-shot CoT consistently outperforms others, reinforcing the
effectiveness of reasoning-driven LLMs. Nonetheless, dataset variability
highlights challenges in model reliability and interpretability. This study
provides a comprehensive benchmark of reasoning-based LLM techniques for mental
health text classification. It offers insights into their potential for
scalable clinical applications while identifying key challenges for future
improvements.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Structured reasoning techniques like Chain-of-Thought and Few-shot CoT improve the accuracy and interpretability of Large Language Models in mental health text classification, outperforming traditional methods on datasets such as Dreaddit and SDCNL.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10095v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBCognitive-Mental-LLM:+Leveraging+Reasoning+in+Large+Language+Models+for+Mental+Health+Prediction+via+Online+Text%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10095v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error</div>
        <div class="paper-authors">Shu-Xun Yang, Cunxiang Wang, Yidong Wang, Xiaotao Gu, Minlie Huang, ...</div>
        <div class="paper-affiliations">Zhipu.AI, Tsinghua University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Mathematical Reasoning Evaluation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Evaluating mathematical capabilities is critical for assessing the overall
performance of large language models (LLMs). However, existing evaluation
methods often focus solely on final answers, resulting in highly inaccurate and
uninterpretable evaluation outcomes, as well as their failure to assess proof
or open-ended problems. To address these issues, we propose a novel
mathematical process evaluation agent based on Tree-of-Error, called
StepMathAgent. This agent incorporates four internal core operations: logical
step segmentation, step scoring, score aggregation and error tree generation,
along with four external extension modules: difficulty calibration, simplicity
evaluation, completeness validation and format assessment. Furthermore, we
introduce StepMathBench, a benchmark comprising 1,000 step-divided process
evaluation instances, derived from 200 high-quality math problems grouped by
problem type, subject category and difficulty level. Experiments on
StepMathBench show that our proposed StepMathAgent outperforms all
state-of-the-art methods, demonstrating human-aligned evaluation preferences
and broad applicability to various scenarios. Our data and code are available
at https://github.com/SHU-XUN/StepMathAgent.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> StepMathAgent introduces a novel Tree-of-Error based approach for evaluating mathematical problem-solving processes in LLMs, outperforming existing methods with high interpretability and human-aligned scores.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10105v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBStepMathAgent:+A+Step-Wise+Agent+for+Evaluating+Mathematical+Processes+through+Tree-of-Error%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10105v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Gumiho: A Hybrid Architecture to Prioritize Early Tokens in Speculative Decoding</div>
        <div class="paper-authors">Jinze Li, Yixing Xu, Haiduo Huang, Xuanwu Yin, Dong Li, ...</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Speculative Decoding in Large Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Speculative decoding (SPD) aims to accelerate the auto-regressive token
generation process of a target Large Language Model (LLM). Some approaches
employ a draft model with multiple heads to predict a sequence of future
tokens, where each head handles a token in the sequence. The target LLM
verifies the predicted sequence and accepts aligned tokens, enabling efficient
multi-token generation. However, existing methods assume that all tokens within
a sequence are equally important, employing identical head structures and
relying on a single-generation paradigm, either serial or parallel. To this
end, we theoretically demonstrate that initial tokens in the draft sequence are
more important than later ones. Building on this insight, we propose Gumiho, a
hybrid model combining serial and parallel heads. Specifically, given the
critical importance of early tokens, we employ a sophisticated Transformer
architecture for the early draft heads in a serial configuration to improve
accuracy. For later tokens, we utilize multiple lightweight MLP heads operating
in parallel to enhance efficiency. By allocating more advanced model structures
and longer running times to the early heads, Gumiho achieves improved overall
performance. The experimental results demonstrate that our method outperforms
existing approaches, fully validating its effectiveness.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Gumiho introduces a hybrid architecture for speculative decoding that prioritizes early tokens using a serial Transformer for accuracy and parallel MLPs for efficiency, outperforming existing methods.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10135v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBGumiho:+A+Hybrid+Architecture+to+Prioritize+Early+Tokens+in+Speculative+Decoding%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10135v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Retrieval-Augmented Generation with Hierarchical Knowledge</div>
        <div class="paper-authors">Haoyu Huang, Yongfeng Huang, Junjie Yang, Zhenyu Pan, Yongqiang Chen, ...</div>
        <div class="paper-affiliations">The Chinese University of Hong Kong, KASMA.ai</div>
        <div class="paper-tag"><strong>Tag:</strong> Hierarchical Knowledge in RAG Systems</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Graph-based Retrieval-Augmented Generation (RAG) methods have significantly
enhanced the performance of large language models (LLMs) in domain-specific
tasks. However, existing RAG methods do not adequately utilize the naturally
inherent hierarchical knowledge in human cognition, which limits the
capabilities of RAG systems. In this paper, we introduce a new RAG approach,
called HiRAG, which utilizes hierarchical knowledge to enhance the semantic
understanding and structure capturing capabilities of RAG systems in the
indexing and retrieval processes. Our extensive experiments demonstrate that
HiRAG achieves significant performance improvements over the state-of-the-art
baseline methods. The code of our proposed method is available at
\href{https://github.com/hhy-huang/HiRAG}{https://github.com/hhy-huang/HiRAG}.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> HiRAG introduces hierarchical knowledge to enhance Retrieval-Augmented Generation (RAG) systems, addressing challenges of distant structural relationships and knowledge gaps between local and global information.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10150v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBRetrieval-Augmented+Generation+with+Hierarchical+Knowledge%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10150v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">"Well, Keep Thinking": Enhancing LLM Reasoning with Adaptive Injection Decoding</div>
        <div class="paper-authors">Hyunbin Jin, Je Won Yeom, Seunghyun Bae, Taesup Kim</div>
        <div class="paper-affiliations">Seoul National University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Decoding Strategies</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large language models (LLMs) exhibit strong reasoning abilities, often
attributed to few-shot or zero-shot chain-of-thought (CoT) prompting. While
effective, these methods require labor-intensive prompt engineering, raising
the question of whether reasoning can be induced without reliance on explicit
prompts. In this work, we unlock the reasoning capabilities of LLMs without
explicit prompting. Inspired by zero-shot CoT and CoT-decoding, we propose a
novel decoding strategy that systematically nudges LLMs to continue reasoning,
thereby preventing immature reasoning processes. Specifically, we monitor the
model's generation and inject a designated phrase whenever it is likely to
conclude its response prematurely, before completing the reasoning process. Our
experimental evaluations on diverse reasoning benchmarks demonstrate that our
proposed strategy substantially improves LLM reasoning capabilities,
highlighting the potential of decoding-based interventions as an alternative to
traditional prompting techniques.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Adaptive Injection Decoding, a novel decoding strategy that enhances LLM reasoning by dynamically injecting a designated phrase to prevent premature termination of reasoning processes, improving performance across diverse reasoning tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10167v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BB%22Well%2C+Keep+Thinking%22:+Enhancing+LLM+Reasoning+with+Adaptive+Injection+Decoding%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10167v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">PRISM: Preference Refinement via Implicit Scene Modeling for 3D Vision-Language Preference-Based Reinforcement Learning</div>
        <div class="paper-authors">Yirong Sun, Yanjun Chen</div>
        <div class="paper-affiliations">The Hong Kong Polytechnic University, Eastern Institute of Technology</div>
        <div class="paper-tag"><strong>Tag:</strong> 3D Vision-Language Models in Robotics</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> We propose PRISM, a novel framework designed to overcome the limitations of
2D-based Preference-Based Reinforcement Learning (PBRL) by unifying 3D point
cloud modeling and future-aware preference refinement. At its core, PRISM
adopts a 3D Point Cloud-Language Model (3D-PC-LLM) to mitigate occlusion and
viewpoint biases, ensuring more stable and spatially consistent preference
signals. Additionally, PRISM leverages Chain-of-Thought (CoT) reasoning to
incorporate long-horizon considerations, thereby preventing the short-sighted
feedback often seen in static preference comparisons. In contrast to
conventional PBRL techniques, this integration of 3D perception and
future-oriented reasoning leads to significant gains in preference agreement
rates, faster policy convergence, and robust generalization across unseen
robotic environments. Our empirical results, spanning tasks such as robotic
manipulation and autonomous navigation, highlight PRISM's potential for
real-world applications where precise spatial understanding and reliable
long-term decision-making are critical. By bridging 3D geometric awareness with
CoT-driven preference modeling, PRISM establishes a comprehensive foundation
for scalable, human-aligned reinforcement learning.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> PRISM introduces a 3D Point Cloud-Language Model and Chain-of-Thought reasoning to enhance Preference-Based Reinforcement Learning by improving spatial understanding and long-term decision-making in robotic tasks.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10177v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBPRISM:+Preference+Refinement+via+Implicit+Scene+Modeling+for+3D+Vision-Language+Preference-Based+Reinforcement+Learning%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10177v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Adaptive Inner Speech-Text Alignment for LLM-based Speech Translation</div>
        <div class="paper-authors">Henglyu Liu, Andong Chen, Kehai Chen, Xuefeng Bai, Meizhi Zhong, ...</div>
        <div class="paper-affiliations">Xi'an University of Technology, Harbin Institute of Technology</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM-based Speech Translation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Recent advancement of large language models (LLMs) has led to significant
breakthroughs across various tasks, laying the foundation for the development
of LLM-based speech translation systems. Existing methods primarily focus on
aligning inputs and outputs across modalities while overlooking deeper semantic
alignment within model representations. To address this limitation, we propose
an Adaptive Inner Speech-Text Alignment (AI-STA) method to bridge the modality
gap by explicitly aligning speech and text representations at selected layers
within LLMs. To achieve this, we leverage the optimal transport (OT) theory to
quantify fine-grained representation discrepancies between speech and text.
Furthermore, we utilize the cross-modal retrieval technique to identify the
layers that are best suited for alignment and perform joint training on these
layers. Experimental results on speech translation (ST) tasks demonstrate that
AI-STA significantly improves the translation performance of large speech-text
models (LSMs), outperforming previous state-of-the-art approaches. Our findings
highlight the importance of inner-layer speech-text alignment in LLMs and
provide new insights into enhancing cross-modal learning.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces an Adaptive Inner Speech-Text Alignment (AI-STA) method to enhance speech translation by aligning speech and text representations at specific layers within large language models, leveraging optimal transport theory and cross-modal retrieval.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10211v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAdaptive+Inner+Speech-Text+Alignment+for+LLM-based+Speech+Translation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10211v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Adaptive Preference Aggregation</div>
        <div class="paper-authors">Benjamin Heymann</div>
        <div class="paper-affiliations">Criteo AI Lab</div>
        <div class="paper-tag"><strong>Tag:</strong> AI Alignment with Social Choice Theory</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> AI alignment, the challenge of ensuring AI systems act in accordance with
human values, has emerged as a critical problem in the development of systems
such as foundation models and recommender systems. Still, the current dominant
approach, reinforcement learning with human feedback (RLHF) faces known
theoretical limitations in aggregating diverse human preferences. Social choice
theory provides a framework to aggregate preferences, but was not developed for
the multidimensional applications typical of AI. Leveraging insights from a
recently published urn process, this work introduces a preference aggregation
strategy that adapts to the user's context and that inherits the good
properties of the maximal lottery, a Condorcet-consistent solution concept.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces Adaptive Preference Aggregation (APA), a novel algorithm for AI alignment that adapts to user context and leverages social choice theory to aggregate diverse human preferences, addressing limitations in reinforcement learning with human feedback (RLHF).</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10215v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAdaptive+Preference+Aggregation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10215v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Assessing the validity of new paradigmatic complexity measures as criterial features for proficiency in L2 writings in English</div>
        <div class="paper-authors">Cyriel Mallart, Andrew Simpkin, Nicolas Ballier, Paula Lissón, Rémi Venant, ...</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> L2 Writing Proficiency Assessment</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> This article addresses Second Language (L2) writing development through an
investigation of new grammatical and structural complexity metrics. We explore
the paradigmatic production in learner English by linking language functions to
specific grammatical paradigms. Using the EFCAMDAT as a gold standard and a
corpus of French learners as an external test set, we employ a supervised
learning framework to operationalise and evaluate seven microsystems. We show
that learner levels are associated with the seven microsystems (MS). Using
ordinal regression modelling for evaluation, the results show that all MS are
significant but yield a low impact if taken individually. However, their
influence is shown to be impactful if taken as a group. These microsystems and
their measurement method suggest that it is possible to use them as part of
broader-purpose CALL systems focused on proficiency assessment.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The study demonstrates that seven grammatical and structural complexity microsystems, when evaluated collectively, can effectively assess proficiency in L2 English writing, suggesting their potential use in broader CALL systems.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10220v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAssessing+the+validity+of+new+paradigmatic+complexity+measures+as+criterial+features+for+proficiency+in+L2+writings+in+English%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10220v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">R.U.Psycho? Robust Unified Psychometric Testing of Language Models</div>
        <div class="paper-authors">Julian Schelb, Orr Borin, David Garcia, Andreas Spitz</div>
        <div class="paper-affiliations">Recosys, University of Konstanz</div>
        <div class="paper-tag"><strong>Tag:</strong> Psychometric Testing of Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Generative language models are increasingly being subjected to psychometric
questionnaires intended for human testing, in efforts to establish their
traits, as benchmarks for alignment, or to simulate participants in social
science experiments. While this growing body of work sheds light on the
likeness of model responses to those of humans, concerns are warranted
regarding the rigour and reproducibility with which these experiments may be
conducted. Instabilities in model outputs, sensitivity to prompt design,
parameter settings, and a large number of available model versions increase
documentation requirements. Consequently, generalization of findings is often
complex and reproducibility is far from guaranteed. In this paper, we present
R.U.Psycho, a framework for designing and running robust and reproducible
psychometric experiments on generative language models that requires limited
coding expertise. We demonstrate the capability of our framework on a variety
of psychometric questionnaires, which lend support to prior findings in the
literature. R.U.Psycho is available as a Python package at
https://github.com/julianschelb/rupsycho.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> R.U.Psycho is a framework designed for robust and reproducible psychometric testing of generative language models, addressing issues of prompt sensitivity and reproducibility.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10229v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBR.U.Psycho?+Robust+Unified+Psychometric+Testing+of+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10229v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">ARLED: Leveraging LED-based ARMAN Model for Abstractive Summarization of Persian Long Documents</div>
        <div class="paper-authors">Samira Zangooei, Amirhossein Darmani, Hossein Farahmand Nezhad, Laya Mahmoudi</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> Long Document Summarization</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The increasing volume of textual data poses challenges in reading and
comprehending large documents, particularly for scholars who need to extract
useful information from research articles. Automatic text summarization has
emerged as a powerful tool to condense lengthy documents into concise and
informative summaries. Depending on the approach used, text summarization can
be categorized as either extractive or abstractive. While extractive methods
are commonly used due to their simplicity, they often miss important
information. On the other hand, Abstractive Summarization can generate more
coherent and informative summaries by understanding the underlying meaning of
the text. Abstractive techniques have gained attention in various languages,
and recent advancements have been achieved through pre-training models such as
BERT, BART, and T5. However, the challenge of summarizing long documents
remains, and alternative models like Longformer have been introduced to address
this limitation. In this context, this paper focuses on abstractive
summarization in the Persian language. The authors introduce a new dataset of
300,000 full-text Persian papers obtained from the Ensani website and apply the
ARMAN model, based on the Longformer architecture, to generate summaries. The
experimental results demonstrate promising performance in Persian text
summarization. The paper provides a comprehensive overview of related work,
discusses the methodology, presents the experimental results, and concludes
with future research directions.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces ARLED, a model leveraging the ARMAN architecture based on Longformer for abstractive summarization of Persian long documents, demonstrating promising results on a new dataset of 300,000 Persian papers.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10233v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBARLED:+Leveraging+LED-based+ARMAN+Model+for+Abstractive+Summarization+of+Persian+Long+Documents%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10233v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">MinorBench: A hand-built benchmark for content-based risks for children</div>
        <div class="paper-authors">Shaun Khoo, Gabriel Chua, Rachel Shong</div>
        <div class="paper-affiliations">Government Technology Agency</div>
        <div class="paper-tag"><strong>Tag:</strong> Child-Centric AI Safety</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Large Language Models (LLMs) are rapidly entering children's lives - through
parent-driven adoption, schools, and peer networks - yet current AI ethics and
safety research do not adequately address content-related risks specific to
minors. In this paper, we highlight these gaps with a real-world case study of
an LLM-based chatbot deployed in a middle school setting, revealing how
students used and sometimes misused the system. Building on these findings, we
propose a new taxonomy of content-based risks for minors and introduce
MinorBench, an open-source benchmark designed to evaluate LLMs on their ability
to refuse unsafe or inappropriate queries from children. We evaluate six
prominent LLMs under different system prompts, demonstrating substantial
variability in their child-safety compliance. Our results inform practical
steps for more robust, child-focused safety mechanisms and underscore the
urgency of tailoring AI systems to safeguard young users.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces MinorBench, a benchmark to evaluate LLMs on their ability to refuse unsafe or inappropriate queries from children, highlighting the need for child-focused AI safety mechanisms.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10242v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBMinorBench:+A+hand-built+benchmark+for+content-based+risks+for+children%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10242v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">LLM Agents Display Human Biases but Exhibit Distinct Learning Patterns</div>
        <div class="paper-authors">Idan Horowitz, Ori Plonsky</div>
        <div class="paper-affiliations">Technion</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Behavioral Biases</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> We investigate the choice patterns of Large Language Models (LLMs) in the
context of Decisions from Experience tasks that involve repeated choice and
learning from feedback, and compare their behavior to human participants. We
find that on the aggregate, LLMs appear to display behavioral biases similar to
humans: both exhibit underweighting rare events and correlation effects.
However, more nuanced analyses of the choice patterns reveal that this happens
for very different reasons. LLMs exhibit strong recency biases, unlike humans,
who appear to respond in more sophisticated ways. While these different
processes may lead to similar behavior on average, choice patterns contingent
on recent events differ vastly between the two groups. Specifically, phenomena
such as ``surprise triggers change" and the ``wavy recency effect of rare
events" are robustly observed in humans, but entirely absent in LLMs. Our
findings provide insights into the limitations of using LLMs to simulate and
predict humans in learning environments and highlight the need for refined
analyses of their behavior when investigating whether they replicate human
decision making tendencies.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> LLMs exhibit human-like behavioral biases in Decisions from Experience tasks but differ in underlying learning patterns, particularly showing strong recency biases unlike humans.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10248v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLLM+Agents+Display+Human+Biases+but+Exhibit+Distinct+Learning+Patterns%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10248v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence</div>
        <div class="paper-authors">Chang Han Low, Ziyue Wang, Tianyi Zhang, Zhitao Zeng, Zhu Zhuo, ...</div>
        <div class="paper-affiliations">Bioinformatics Institute (BII), Agency for Science, Technology and Research (A*STAR), University College London, National University of Singapore</div>
        <div class="paper-tag"><strong>Tag:</strong> Multi-Agent Systems in Surgical Robotics</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Integration of Vision-Language Models (VLMs) in surgical intelligence is
hindered by hallucinations, domain knowledge gaps, and limited understanding of
task interdependencies within surgical scenes, undermining clinical
reliability. While recent VLMs demonstrate strong general reasoning and
thinking capabilities, they still lack the domain expertise and task-awareness
required for precise surgical scene interpretation. Although Chain-of-Thought
(CoT) can structure reasoning more effectively, current approaches rely on
self-generated CoT steps, which often exacerbate inherent domain gaps and
hallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent
framework that delivers transparent, interpretable insights for most tasks in
robotic-assisted surgery. By employing specialized CoT prompts across five
tasks: instrument recognition, action recognition, action prediction, patient
data extraction, and outcome assessment, SurgRAW mitigates hallucinations
through structured, domain-aware reasoning. Retrieval-Augmented Generation
(RAG) is also integrated to external medical knowledge to bridge domain gaps
and improve response reliability. Most importantly, a hierarchical agentic
system ensures that CoT-embedded VLM agents collaborate effectively while
understanding task interdependencies, with a panel discussion mechanism
promotes logical consistency. To evaluate our method, we introduce
SurgCoTBench, the first reasoning-based dataset with structured frame-level
annotations. With comprehensive experiments, we demonstrate the effectiveness
of proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12
robotic procedures, achieving the state-of-the-art performance and advancing
explainable, trustworthy, and autonomous surgical assistance.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> SurgRAW is a multi-agent framework using Chain-of-Thought reasoning and Retrieval-Augmented Generation to enhance surgical intelligence by improving accuracy, explainability, and reliability in tasks like instrument recognition and outcome assessment.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10265v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBSurgRAW:+Multi-Agent+Workflow+with+Chain-of-Thought+Reasoning+for+Surgical+Intelligence%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10265v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">An Expanded Massive Multilingual Dataset for High-Performance Language Technologies</div>
        <div class="paper-authors">Laurie Burchell, Ona de Gibert, Nikolay Arefyev, Mikko Aulamo, Marta Bañón, ...</div>
        <div class="paper-affiliations">University of Oslo, University of Helsinki, University of Turku, Charles University, Prompsit Language Engineering, ...</div>
        <div class="paper-tag"><strong>Tag:</strong> Multilingual Dataset Construction</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Training state-of-the-art large language models requires vast amounts of
clean and diverse textual data. However, building suitable multilingual
datasets remains a challenge. In this work, we present HPLT v2, a collection of
high-quality multilingual monolingual and parallel corpora. The monolingual
portion of the data contains 8T tokens covering 193 languages, while the
parallel data contains 380M sentence pairs covering 51 languages. We document
the entire data pipeline and release the code to reproduce it. We provide
extensive analysis of the quality and characteristics of our data. Finally, we
evaluate the performance of language models and machine translation systems
trained on HPLT v2, demonstrating its value.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> HPLT v2 introduces a massive multilingual dataset with 8T tokens across 193 languages and 380M parallel sentence pairs, enabling high-performance language and machine translation models.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10267v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBAn+Expanded+Massive+Multilingual+Dataset+for+High-Performance+Language+Technologies%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10267v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Wikipedia is Not a Dictionary, Delete! Text Classification as a Proxy for Analysing Wiki Deletion Discussions</div>
        <div class="paper-authors">Hsuvas Borkakoty, Luis Espinosa-Anke</div>
        <div class="paper-affiliations">AMPLYFI, Cardiff University</div>
        <div class="paper-tag"><strong>Tag:</strong> Automated Content Moderation in Collaborative Platforms</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Automated content moderation for collaborative knowledge hubs like Wikipedia
or Wikidata is an important yet challenging task due to multiple factors. In
this paper, we construct a database of discussions happening around articles
marked for deletion in several Wikis and in three languages, which we then use
to evaluate a range of LMs on different tasks (from predicting the outcome of
the discussion to identifying the implicit policy an individual comment might
be pointing to). Our results reveal, among others, that discussions leading to
deletion are easier to predict, and that, surprisingly, self-produced tags
(keep, delete or redirect) don't always help guiding the classifiers,
presumably because of users' hesitation or deliberation within comments.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper analyzes deletion discussions across multiple Wiki platforms and languages, demonstrating that pre-trained language models can effectively predict outcomes and improve automated content moderation.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10294v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBWikipedia+is+Not+a+Dictionary%2C+Delete%21+Text+Classification+as+a+Proxy+for+Analysing+Wiki+Deletion+Discussions%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10294v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Proceedings of the ISCA/ITG Workshop on Diversity in Large Speech and Language Models</div>
        <div class="paper-authors">Sebastian Möller, Pia Knoeferle, Britta Schulte, Nils Feldhus</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Generalization to Under-represented Languages</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Machine learning techniques have conquered many different tasks in speech and
natural language processing, such as speech recognition, information
extraction, text and speech generation, and human machine interaction using
natural language or speech (chatbots). Modern techniques typically rely on
large models for representing general knowledge of one or several languages
(Large Language Models, LLMs), or for representing speech and general audio
characteristics. These models have been trained with large amounts of speech
and language data, typically including web content. When humans interact with
such technologies, the effectiveness of the interaction will be influenced by
how far humans make use of the same type of language the models have been
trained on or, in other words, if the models are able to generalize to the
language used by humans when interacting with the technology. This may lead to
some gradual forms of adaptation in human speech and language production, and
users who do not adapt may be excluded from efficient use of such technologies.
On top of this, as commercial model development follows market needs,
under-represented languages and dialects/sociolects may decrease in terms of
priorities. Furthermore, for many lesser spoken languages the necessary data is
not available, which will worsen a digital divide in speech and language
technology usage. The workshop sets out to discuss this problem based on
scientific contributions from the perspective of computer science and
linguistics (including computational linguistics and NLP).</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The workshop discusses the challenges of diversity and generalization in large speech and language models, focusing on under-represented languages and the digital divide in technology usage.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10298v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBProceedings+of+the+ISCA/ITG+Workshop+on+Diversity+in+Large+Speech+and+Language+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10298v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">KV-Distill: Nearly Lossless Learnable Context Compression for LLMs</div>
        <div class="paper-authors">Vivek Chari, Guanghui Qin, Benjamin Van Durme</div>
        <div class="paper-affiliations">Johns Hopkins University, Microsoft</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Context Compression</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Sequence-to-sequence tasks often benefit from long contexts, but the
quadratic complexity of self-attention in standard Transformers renders this
non-trivial. During generation, temporary representations -stored in the
so-called KV cache-account for a large portion of GPU memory usage and scale
linearly with context length. We introduce KV-Distill, a Transformer
compression framework that distills long context KV caches into significantly
shorter representations in a question-independent fashion. KV-Distill can be
trained as a parameter-efficient adaptor for pretrained models, and enables the
compression of arbitrary spans of a context while preserving pre-trained model
capabilities. We treat a compressed-uncompressed cache as a student-teacher
pairing and apply a KL-type divergence to match the generated outputs.
KV-Distill outperforms other compression techniques in worst-case extractive
tasks and approaches uncompressed performance in long context question
answering and summarization, and it can be fine-tuned on domain-specific
contexts to reduce lengths by up to 99% while preserving downstream
performance. We demonstrate the generalizability of KV-Distill across various
model sizes and architectures.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> KV-Distill introduces a Transformer compression framework that distills long context KV caches into shorter representations, enabling nearly lossless compression while preserving model performance across various tasks and architectures.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10337v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBKV-Distill:+Nearly+Lossless+Learnable+Context+Compression+for+LLMs%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10337v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">New Trends for Modern Machine Translation with Large Reasoning Models</div>
        <div class="paper-authors">Sinuo Liu, Chenyang Lyu, Minghao Wu, Longyue Wang, Weihua Luo, ...</div>
        <div class="paper-affiliations">University of Edinburgh, Alibaba International Digital Commerce</div>
        <div class="paper-tag"><strong>Tag:</strong> Chain-of-Thought Reasoning in Machine Translation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Recent advances in Large Reasoning Models (LRMs), particularly those
leveraging Chain-of-Thought reasoning (CoT), have opened brand new possibility
for Machine Translation (MT). This position paper argues that LRMs
substantially transformed traditional neural MT as well as LLMs-based MT
paradigms by reframing translation as a dynamic reasoning task that requires
contextual, cultural, and linguistic understanding and reasoning. We identify
three foundational shifts: 1) contextual coherence, where LRMs resolve
ambiguities and preserve discourse structure through explicit reasoning over
cross-sentence and complex context or even lack of context; 2) cultural
intentionality, enabling models to adapt outputs by inferring speaker intent,
audience expectations, and socio-linguistic norms; 3) self-reflection, LRMs can
perform self-reflection during the inference time to correct the potential
errors in translation especially extremely noisy cases, showing better
robustness compared to simply mapping X->Y translation. We explore various
scenarios in translation including stylized translation, document-level
translation and multimodal translation by showcasing empirical examples that
demonstrate the superiority of LRMs in translation. We also identify several
interesting phenomenons for LRMs for MT including auto-pivot translation as
well as the critical challenges such as over-localisation in translation and
inference efficiency. In conclusion, we think that LRMs redefine translation
systems not merely as text converters but as multilingual cognitive agents
capable of reasoning about meaning beyond the text. This paradigm shift reminds
us to think of problems in translation beyond traditional translation scenarios
in a much broader context with LRMs - what we can achieve on top of it.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> Large Reasoning Models (LRMs) redefine Machine Translation by integrating reasoning capabilities, enabling contextual coherence, cultural intentionality, and self-reflection, transforming translation systems into multilingual cognitive agents.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10351v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBNew+Trends+for+Modern+Machine+Translation+with+Large+Reasoning+Models%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10351v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">A Hybrid Architecture with Efficient Fine Tuning for Abstractive Patent Document Summarization</div>
        <div class="paper-authors">Nevidu Jayatilleke, Ruvan Weerasinghe</div>
        <div class="paper-affiliations">Unknown Affiliation</div>
        <div class="paper-tag"><strong>Tag:</strong> LoRA Fine-Tuning in NLP</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Automatic patent summarization approaches that help in the patent analysis
and comprehension procedure are in high demand due to the colossal growth of
innovations. The development of natural language processing (NLP), text mining,
and deep learning has notably amplified the efficacy of text summarization
models for abundant types of documents. Summarizing patent text remains a
pertinent challenge due to the labyrinthine writing style of these documents,
which includes technical and legal intricacies. Additionally, these patent
document contents are considerably lengthier than archetypal documents, which
intricates the process of extracting pertinent information for summarization.
Embodying extractive and abstractive text summarization methodologies into a
hybrid framework, this study proposes a system for efficiently creating
abstractive summaries of patent records. The procedure involves leveraging the
LexRank graph-based algorithm to retrieve the important sentences from input
parent texts, then utilizing a Bidirectional Auto-Regressive Transformer (BART)
model that has been fine-tuned using Low-Ranking Adaptation (LoRA) for
producing text summaries. This is accompanied by methodical testing and
evaluation strategies. Furthermore, the author employed certain meta-learning
techniques to achieve Domain Generalization (DG) of the abstractive component
across multiple patent fields.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper proposes a hybrid architecture combining LexRank and a fine-tuned BART model with LoRA for efficient abstractive summarization of lengthy and complex patent documents, enhanced by meta-learning for domain generalization.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10354v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBA+Hybrid+Architecture+with+Efficient+Fine+Tuning+for+Abstractive+Patent+Document+Summarization%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10354v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Do I look like a `cat.n.01` to you? A Taxonomy Image Generation Benchmark</div>
        <div class="paper-authors">Viktor Moskvoretskii, Alina Lobanova, Ekaterina Neminova, Chris Biemann, Alexander Panchenko, ...</div>
        <div class="paper-affiliations">HSE University, Skoltech, University of Hamburg, AIRI</div>
        <div class="paper-tag"><strong>Tag:</strong> Text-to-Image Models for Taxonomy Visualization</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> This paper explores the feasibility of using text-to-image models in a
zero-shot setup to generate images for taxonomy concepts. While text-based
methods for taxonomy enrichment are well-established, the potential of the
visual dimension remains unexplored. To address this, we propose a
comprehensive benchmark for Taxonomy Image Generation that assesses models'
abilities to understand taxonomy concepts and generate relevant, high-quality
images. The benchmark includes common-sense and randomly sampled WordNet
concepts, alongside the LLM generated predictions. The 12 models are evaluated
using 9 novel taxonomy-related text-to-image metrics and human feedback.
Moreover, we pioneer the use of pairwise evaluation with GPT-4 feedback for
image generation. Experimental results show that the ranking of models differs
significantly from standard T2I tasks. Playground-v2 and FLUX consistently
outperform across metrics and subsets and the retrieval-based approach performs
poorly. These findings highlight the potential for automating the curation of
structured data resources.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces a benchmark for evaluating text-to-image models' ability to generate images for taxonomy concepts, showing that Playground-v2 and FLUX outperform other models.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10357v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDo+I+look+like+a+%60cat.n.01%60+to+you?+A+Taxonomy+Image+Generation+Benchmark%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10357v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">G-Boost: Boosting Private SLMs with General LLMs</div>
        <div class="paper-authors">Yijiang Fan, Yuren Mao, Longbin Lai, Ying Zhang, Zhengping Qian, ...</div>
        <div class="paper-affiliations">Alibaba Cloud, Tongyi Lab Alibaba Group, Zhejiang University, Zhejiang Gongshang University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Collaborative Inference</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> Due to the limited computational resources, most Large Language Models (LLMs)
developers can only fine-tune Small Language Models (SLMs) on their own data.
These private SLMs typically have limited effectiveness. To boost the
performance of private SLMs, this paper proposes to ask general LLMs for help.
The general LLMs can be APIs or larger LLMs whose inference cost the developers
can afford. Specifically, we propose the G-Boost framework where a private SLM
adaptively performs collaborative inference with a general LLM under the guide
of process reward. Experiments demonstrate that our framework can significantly
boost the performance of private SLMs.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> G-Boost is a framework that enhances the performance of private Small Language Models (SLMs) by adaptively collaborating with general Large Language Models (LLMs) under the guidance of a process reward model.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10367v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBG-Boost:+Boosting+Private+SLMs+with+General+LLMs%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10367v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">VisTai: Benchmarking Vision-Language Models for Traditional Chinese in Taiwan</div>
        <div class="paper-authors">Zhi Rui Tam, Ya-Ting Pai, Yen-Wei Lee</div>
        <div class="paper-affiliations">Independent Researcher, University of Illinois Urbana-Champaign</div>
        <div class="paper-tag"><strong>Tag:</strong> Multilingual Vision-Language Models</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="full-star">⭐</span><span class="half-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> In this paper, we propose a comprehensive evaluation benchmark for Visual
Language Models (VLM) in Traditional Chinese. Our evaluation suite, the first
of its kind, contains two complementary components: (1) VisTai-MCQ, a
collection of manually curated exam multi-choice questions from 21 academic
subjects designed to test the broad knowledge and reasoning capabilities of
VLMs; and (2) VisTai-Dialogue, an open dialogue benchmark comprising 131
image-question pairs manually created to evaluate VLMs' ability in free-form
dialogue generation within Taiwanese cultural contexts. These benchmarks
address a critical gap in the evaluation landscape, where existing benchmarks
predominantly focus on English or Simplified Chinese, neglecting the unique
linguistic and cultural aspects of Traditional Chinese used in regions like
Taiwan and Hong Kong. Our analysis reveals significant performance differences
across various VLMs and highlights specific challenges in processing
Traditional Chinese visual content.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces VisTai-MCQ and VisTai-Dialogue, the first benchmarks for evaluating Vision-Language Models in Traditional Chinese, highlighting performance gaps and challenges in processing Traditional Chinese visual content.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10427v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBVisTai:+Benchmarking+Vision-Language+Models+for+Traditional+Chinese+in+Taiwan%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10427v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">DynaCode: A Dynamic Complexity-Aware Code Benchmark for Evaluating Large Language Models in Code Generation</div>
        <div class="paper-authors">Wenhao Hu, Jinhao Duan, Chunchen Wei, Li Zhang, Yue Zhang, ...</div>
        <div class="paper-affiliations">University of Electronic Science and Technology of China, Drexel University</div>
        <div class="paper-tag"><strong>Tag:</strong> LLM Code Generation Evaluation</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> The rapid advancement of large language models (LLMs) has significantly
improved their performance in code generation tasks. However, existing code
benchmarks remain static, consisting of fixed datasets with predefined
problems. This makes them vulnerable to memorization during training, where
LLMs recall specific test cases instead of generalizing to new problems,
leading to data contamination and unreliable evaluation results. To address
these issues, we introduce DynaCode, a dynamic, complexity-aware benchmark that
overcomes the limitations of static datasets. DynaCode evaluates LLMs
systematically using a complexity-aware metric, incorporating both code
complexity and call-graph structures. DynaCode achieves large-scale diversity,
generating up to 189 million unique nested code problems across four distinct
levels of code complexity, referred to as units, and 16 types of call graphs.
Results on 12 latest LLMs show an average performance drop of 16.8% to 45.7%
compared to MBPP+, a static code generation benchmark, with performance
progressively decreasing as complexity increases. This demonstrates DynaCode's
ability to effectively differentiate LLMs. Additionally, by leveraging call
graphs, we gain insights into LLM behavior, particularly their preference for
handling subfunction interactions within nested code.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> DynaCode is a dynamic, complexity-aware benchmark for evaluating large language models in code generation, addressing data contamination and providing a scalable framework for comprehensive LLM evaluation.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10452v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBDynaCode:+A+Dynamic+Complexity-Aware+Code+Benchmark+for+Evaluating+Large+Language+Models+in+Code+Generation%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10452v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond</div>
        <div class="paper-authors">Liang Wen, Yunke Cai, Fenrui Xiao, Xin He, Qi An, ...</div>
        <div class="paper-affiliations">Qiyuan Tech, Renmin University</div>
        <div class="paper-tag"><strong>Tag:</strong> Curriculum Learning for Long-Chain-of-Thought Reasoning</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> This paper presents our work on the Light-R1 series, with models, data, and
code all released.
  We first focus on training long COT models from scratch, specifically
starting from models initially lacking long COT capabilities. Using a
curriculum training recipe consisting of two-stage SFT and semi-on-policy DPO,
we train our model Light-R1-32B from Qwen2.5-32B-Instruct, resulting in
superior math performance compared to DeepSeek-R1-Distill-Qwen-32B. Despite
being trained exclusively on math data, Light-R1-32B shows strong
generalization across other domains. In the subsequent phase of this work, we
highlight the significant benefit of the 3k dataset constructed for the second
SFT stage on enhancing other models. By fine-tuning DeepSeek-R1-Distilled
models using this dataset, we obtain new SOTA models in 7B and 14B, while the
32B model, Light-R1-32B-DS performed comparably to QwQ-32B and DeepSeek-R1.
  Furthermore, we extend our work by applying reinforcement learning,
specifically GRPO, on long-COT models to further improve reasoning performance.
We successfully train our final Light-R1-14B-DS with RL, achieving SOTA
performance among 14B parameter models in math. With AIME24 & 25 scores of 74.0
and 60.2 respectively, Light-R1-14B-DS surpasses even many 32B models and
DeepSeek-R1-Distill-Llama-70B. Its RL training also exhibits well expected
behavior, showing simultaneous increase in response length and reward score.
  The Light-R1 series of work validates training long-COT models from scratch,
showcases the art in SFT data and releases SOTA models from RL.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The Light-R1 series introduces a cost-effective curriculum using SFT, DPO, and RL to train long-chain-of-thought mathematical reasoning models from scratch, achieving SOTA performance in 7B, 14B, and 32B parameter models.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10460v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBLight-R1:+Curriculum+SFT%2C+DPO+and+RL+for+Long+COT+from+Scratch+and+Beyond%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10460v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br><br>
    <div class="paper-block">
        <div class="paper-title">Statistical Analysis of Sentence Structures through ASCII, Lexical Alignment and PCA</div>
        <div class="paper-authors">Abhijeet Sahdev</div>
        <div class="paper-affiliations">New Jersey Institute of Technology</div>
        <div class="paper-tag"><strong>Tag:</strong> ASCII-based Text Analysis</div>
        <div class="paper-score"><strong>Score:</strong> <div class="star-wrapper"><span class="full-star">⭐</span></div></div>
        <div class="paper-abstract"><strong>Abstract:</strong> While utilizing syntactic tools such as parts-of-speech (POS) tagging has
helped us understand sentence structures and their distribution across diverse
corpora, it is quite complex and poses a challenge in natural language
processing (NLP). This study focuses on understanding sentence structure
balance - usages of nouns, verbs, determiners, etc - harmoniously without
relying on such tools. It proposes a novel statistical method that uses
American Standard Code for Information Interchange (ASCII) codes to represent
text of 11 text corpora from various sources and their lexical category
alignment after using their compressed versions through PCA, and analyzes the
results through histograms and normality tests such as Shapiro-Wilk and
Anderson-Darling Tests. By focusing on ASCII codes, this approach simplifies
text processing, although not replacing any syntactic tools but complementing
them by offering it as a resource-efficient tool for assessing text balance.
The story generated by Grok shows near normality indicating balanced sentence
structures in LLM outputs, whereas 4 out of the remaining 10 pass the normality
tests. Further research could explore potential applications in text quality
evaluation and style analysis with syntactic integration for more broader
tasks.</div>
        <div class="paper-tldr"><strong>TLDR:</strong> The paper introduces a novel statistical method using ASCII codes and PCA to analyze sentence structure balance across diverse text corpora, demonstrating its potential for high-level text analysis without relying on complex syntactic tools.</div>
        <div class="paper-actions">
            <a href="javascript:void(0)" onclick="openModal('https://arxiv.org/pdf/2503.10470v1')">PDF</a>
            <a href="javascript:void(0)" onclick="openModal('https://kimi.moonshot.cn/_prefill_chat?prefill_prompt=%E8%AF%B7%E4%BD%A0%E9%98%85%E8%AF%BBStatistical+Analysis+of+Sentence+Structures+through+ASCII%2C+Lexical+Alignment+and+PCA%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%EF%BC%8C%E9%93%BE%E6%8E%A5%E6%98%AF+https://arxiv.org/pdf/2503.10470v1+%EF%BC%8C%E5%B9%B6%E5%9B%9E%E7%AD%94%E4%BB%A5%E4%B8%8B%E9%97%AE%E9%A2%98%EF%BC%9A%0A%2A%2AQ1.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E8%AF%95%E5%9B%BE%E8%A7%A3%E5%86%B3%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F%2A%2A%0A%2A%2AQ2.+%E8%BF%99%E6%98%AF%E4%B8%80%E4%B8%AA%E6%96%B0%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F%E5%A6%82%E6%9E%9C%E6%9C%89%E7%9B%B8%E5%85%B3%E7%A0%94%E7%A9%B6%EF%BC%8C%E8%AF%B7%E7%BB%99%E5%87%BA%E5%B9%B6%E6%80%BB%E7%BB%93%E6%96%B9%E6%B3%95%2A%2A%0A%2A%2AQ3.+%E6%9C%AC%E6%96%87%E8%AF%95%E5%9B%BE%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%2A%2A%0A%2A%2AQ4.+%E8%BF%99%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%90%E5%87%BA%E4%BA%86%E4%BB%80%E4%B9%88%E6%96%B0%E7%9A%84%E6%83%B3%E6%B3%95%E3%80%81%E6%96%B9%E6%B3%95%E6%88%96%E6%A8%A1%E5%9E%8B%EF%BC%9F%E4%B8%8E%E4%BB%A5%E5%89%8D%E7%9A%84%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94%EF%BC%8C%E6%9C%89%E4%BB%80%E4%B9%88%E7%89%B9%E7%82%B9%E5%92%8C%E4%BC%98%E5%8A%BF%EF%BC%9F%2A%2A%0A%2A%2AQ5.+%E8%AE%BA%E6%96%87%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%AA%8C%E6%98%AF%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E7%9A%84%EF%BC%9F%2A%2A%0A%2A%2AQ6.+%E5%AE%9E%E9%AA%8C%E5%92%8C%E7%BB%93%E6%9E%9C%E6%98%AF%E5%90%A6%E5%BE%88%E5%A5%BD%E5%9C%B0%E6%94%AF%E6%8C%81%E4%BA%86%E9%9C%80%E8%A6%81%E9%AA%8C%E8%AF%81%E7%9A%84%E7%A7%91%E5%AD%A6%E5%81%87%E8%AE%BE%2A%2A%0A%E5%9B%9E%E7%AD%94%E6%97%B6%E8%AF%B7%E5%85%88%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98%EF%BC%8C%E5%86%8D%E8%BF%9B%E8%A1%8C%E5%AF%B9%E5%BA%94%E7%9A%84%E5%9B%9E%E7%AD%94%E3%80%82&system_prompt=%E4%BD%A0%E6%98%AF%E4%B8%80%E4%B8%AA%E5%AD%A6%E6%9C%AF%E4%B8%93%E5%AE%B6%EF%BC%8C%E8%AF%B7%E4%BD%A0%E4%BB%94%E7%BB%86%E9%98%85%E8%AF%BB%E5%90%8E%E7%BB%AD%E9%93%BE%E6%8E%A5%E4%B8%AD%E7%9A%84%E8%AE%BA%E6%96%87%EF%BC%8C%E5%B9%B6%E5%AF%B9%E7%94%A8%E6%88%B7%E7%9A%84%E9%97%AE%E9%A2%98%E8%BF%9B%E8%A1%8C%E4%B8%93%E4%B8%9A%E7%9A%84%E5%9B%9E%E7%AD%94%EF%BC%8C%E4%B8%8D%E8%A6%81%E5%87%BA%E7%8E%B0%E7%AC%AC%E4%B8%80%E4%BA%BA%E7%A7%B0%EF%BC%8C%E5%BD%93%E6%B6%89%E5%8F%8A%E5%88%B0%E5%88%86%E7%82%B9%E5%9B%9E%E7%AD%94%E6%97%B6%EF%BC%8C%E9%BC%93%E5%8A%B1%E4%BD%A0%E4%BB%A5markdown%E6%A0%BC%E5%BC%8F%E8%BE%93%E5%87%BA%E3%80%82%E5%AF%B9%E4%BA%8E%E5%BC%95%E7%94%A8%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E4%BD%A0%E9%9C%80%E8%A6%81%E5%8F%8A%E6%97%B6%E5%9C%A8%E5%BC%95%E7%94%A8%E5%86%85%E5%AE%B9%E5%90%8E%E7%BB%99%E5%87%BA%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5%E3%80%82&send_immediately=true&force_search=true')">Kimi</a>
            
            <span class="heart-btn" onclick="toggleHeart(this)">❤️</span>
        </div>
    </div>
    </br>
  </div>

  <div class="footer">
    <p>To unsubscribe, remove your email in your Github Action setting.</p>
    <p>To have a full reading experience, <a href='https://xiangsam.github.io/arxiv-daily/'>visit this page</a> in a modern brower.</p>
    <p>&copy; 2023 Research Digest. All rights reserved.</p>
  </div>
</div>

<!-- Toast 提示条 -->
<div class="toast" id="toast">Added to favorites!</div>

<!-- 模态框 -->
<div class="modal" id="modal">
  <div class="modal-content">
    <div class="modal-actions">
      <button class="modal-button" onclick="openInNewTab()" title="Open in new tab">
        <i class="fas fa-external-link-alt"></i>
      </button>
      <button class="modal-button close" onclick="closeModal()" title="Close">
        <i class="fas fa-times"></i>
      </button>
    </div>
    <iframe class="modal-iframe" id="modal-iframe" src=""></iframe>
  </div>
</div>

<a href="#" class="back-to-top">↑</a>

<script>
  // 检测是否在浏览器中正常加载
  function isNormalBrowserLoad() {
    // 检查是否可以执行JavaScript
    if (typeof window!== 'undefined' && 'location' in window) {
      return true;
    }
    return false;
  }

  // 隐藏提示条
  if (isNormalBrowserLoad()) {
    const prompt = document.getElementById('browser-prompt');
    prompt.style.display = 'none'; // 隐藏提示条
  }
  
  // 动态加载效果
  document.addEventListener('DOMContentLoaded', function () {
    const paperBlocks = document.querySelectorAll('.paper-block');
    paperBlocks.forEach((block, index) => {
      setTimeout(() => {
        block.classList.add('visible');
      }, index * 200);
    });
  });

  // 回到顶部按钮
  const backToTopButton = document.querySelector('.back-to-top');
  backToTopButton.addEventListener('click', (e) => {
    e.preventDefault();
    window.scrollTo({ top: 0, behavior: 'smooth' });
  });

  // 心形按钮点击提示
  function toggleHeart(button) {
    button.classList.toggle('active');
    showToast('Added to favorites!');
  }

  // 显示 Toast 提示
  function showToast(message) {
    const toast = document.getElementById('toast');
    toast.textContent = message;
    toast.classList.add('visible');
    setTimeout(() => {
      toast.classList.remove('visible');
    }, 3000); // 3 秒后消失
  }
  
  // 打开模态框
  function openModal(url) {
    const modal = document.getElementById('modal');
    const iframe = document.getElementById('modal-iframe');
    iframe.src = url;
    modal.classList.add('visible');
  }

  // 关闭模态框
  function closeModal() {
    const modal = document.getElementById('modal');
    const iframe = document.getElementById('modal-iframe');
    iframe.src = ''; // 清空 iframe 内容
    modal.classList.remove('visible');
  }

  // 在新标签页打开
  function openInNewTab() {
    const iframe = document.getElementById('modal-iframe');
    const url = iframe.src;
    if (url) {
      window.open(url, '_blank');
    }
  }
</script>

</body>
</html>
